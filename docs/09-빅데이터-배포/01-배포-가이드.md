# ë¹…ë°ì´í„° ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” DataOps ëŒ€ì‹œë³´ë“œì— í•„ìš”í•œ ë¹…ë°ì´í„° ì• í”Œë¦¬ì¼€ì´ì…˜ì„ Kubernetes í´ëŸ¬ìŠ¤í„°ì— ë°°í¬í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### ë°°í¬ ì• í”Œë¦¬ì¼€ì´ì…˜

| ì• í”Œë¦¬ì¼€ì´ì…˜ | ìš©ë„ | Namespace | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ |
|------------|------|-----------|------------|
| **Apache Spark** | ë°°ì¹˜/ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬ | `spark` | Prometheus Metrics |
| **Apache Kafka** | ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° | `kafka` | JMX Exporter |
| **Apache Airflow** | ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | `airflow` | StatsD â†’ Prometheus |
| **Trino** | ë¶„ì‚° ì¿¼ë¦¬ ì—”ì§„ | `trino` | JMX Exporter |

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Data Ingestion"
        Kafka[Apache Kafka<br/>Event Streaming]
    end

    subgraph "Data Processing"
        Spark[Apache Spark<br/>Batch/Streaming]
        Airflow[Apache Airflow<br/>Workflow]
    end

    subgraph "Data Query"
        Trino[Trino<br/>SQL Engine]
    end

    subgraph "Storage"
        S3[MinIO S3<br/>Object Storage]
        Iceberg[Apache Iceberg<br/>Table Format]
    end

    subgraph "Monitoring"
        Prometheus[Prometheus<br/>Metrics]
        Grafana[Grafana<br/>Dashboards]
    end

    Kafka -->|Stream| Spark
    Spark -->|Write| Iceberg
    Iceberg -->|Store| S3
    Trino -->|Query| Iceberg
    Airflow -->|Orchestrate| Spark
    Airflow -->|Orchestrate| Trino

    Spark -.->|Metrics| Prometheus
    Kafka -.->|Metrics| Prometheus
    Airflow -.->|Metrics| Prometheus
    Trino -.->|Metrics| Prometheus
    Prometheus -->|Visualize| Grafana
```

---

## ğŸš€ ë°°í¬ ë°©ë²•

### ì˜µì…˜ 1: ArgoCD GitOps ë°°í¬ (ê¶Œì¥)

#### 1. Git Repository ì¤€ë¹„

```bash
# í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
ls -la /root/develop/thanos/deploy-new/

deploy-new/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ values.yaml
â”‚   â”‚   â””â”€â”€ servicemonitor.yaml
â”‚   â””â”€â”€ kafka/
â”‚       â”œâ”€â”€ kustomization.yaml
â”‚       â””â”€â”€ values.yaml
â””â”€â”€ overlays/
    â””â”€â”€ cluster-01-central/
        â”œâ”€â”€ spark/
        â”‚   â”œâ”€â”€ kustomization.yaml
        â”‚   â”œâ”€â”€ namespace.yaml
        â”‚   â””â”€â”€ values-patch.yaml
        â””â”€â”€ kafka/
            â”œâ”€â”€ kustomization.yaml
            â””â”€â”€ namespace.yaml
```

#### 2. Git Repositoryì— Push

```bash
cd /root/develop/thanos

# Git ì´ˆê¸°í™” (ì²˜ìŒì¸ ê²½ìš°)
git init
git add .
git commit -m "feat: Add BigData applications (Spark, Kafka, Airflow, Trino)"

# Remote Repository ì„¤ì •
git remote add origin https://github.com/your-org/thanos-multi-cluster.git
git branch -M main
git push -u origin main
```

#### 3. ArgoCD Application ìƒì„±

```bash
# Spark ë°°í¬
kubectl apply -f argocd/applications/bigdata/spark.yaml

# Kafka ë°°í¬
kubectl apply -f argocd/applications/bigdata/kafka.yaml

# ìƒíƒœ í™•ì¸
kubectl get applications -n argocd
```

#### 4. ArgoCD UIì—ì„œ Sync

1. ArgoCD UI ì ‘ì†: http://argocd.k8s-cluster-01.miribit.lab
2. Applications â†’ `spark` ì„ íƒ
3. `SYNC` ë²„íŠ¼ í´ë¦­
4. `SYNCHRONIZE` í™•ì¸

---

### ì˜µì…˜ 2: Kustomize ì§ì ‘ ë°°í¬

#### Apache Spark ë°°í¬

```bash
# Namespace ìƒì„±
kubectl create namespace spark

# Kustomize ë¹Œë“œ ë° ë°°í¬
kubectl apply -k /root/develop/thanos/deploy-new/overlays/cluster-01-central/spark

# ë°°í¬ í™•ì¸
kubectl get pods -n spark
kubectl get svc -n spark
```

**ì˜ˆìƒ ì¶œë ¥:**
```
NAME                    READY   STATUS    RESTARTS   AGE
spark-master-0          1/1     Running   0          2m
spark-worker-0          1/1     Running   0          2m
spark-worker-1          1/1     Running   0          2m
spark-worker-2          1/1     Running   0          2m
```

#### Apache Kafka ë°°í¬

```bash
# Namespace ìƒì„±
kubectl create namespace kafka

# Kustomize ë¹Œë“œ ë° ë°°í¬
kubectl apply -k /root/develop/thanos/deploy-new/overlays/cluster-01-central/kafka

# ë°°í¬ í™•ì¸
kubectl get pods -n kafka
```

**ì˜ˆìƒ ì¶œë ¥:**
```
NAME        READY   STATUS    RESTARTS   AGE
kafka-0     1/1     Running   0          3m
kafka-1     1/1     Running   0          3m
kafka-2     1/1     Running   0          3m
```

---

## ğŸ” ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸

### Prometheusì—ì„œ ë©”íŠ¸ë¦­ í™•ì¸

```bash
# Spark ë©”íŠ¸ë¦­ í™•ì¸
kubectl exec -n monitoring prometheus-kube-prometheus-stack-prometheus-0 -- \
  wget -q -O- 'http://localhost:9090/api/v1/query?query=spark_application_running' | jq

# Kafka ë©”íŠ¸ë¦­ í™•ì¸
kubectl exec -n monitoring prometheus-kube-prometheus-stack-prometheus-0 -- \
  wget -q -O- 'http://localhost:9090/api/v1/query?query=kafka_server_brokertopicmetrics_messagesin_total' | jq
```

### ServiceMonitor í™•ì¸

```bash
# ServiceMonitor ëª©ë¡
kubectl get servicemonitor -n spark
kubectl get servicemonitor -n kafka

# ServiceMonitor ìƒì„¸
kubectl describe servicemonitor spark-metrics -n spark
```

### Prometheus Targets í™•ì¸

1. Prometheus UI ì ‘ì†: http://prometheus.k8s-cluster-01.miribit.lab
2. Status â†’ Targets
3. `spark` ë° `kafka` Endpoint ìƒíƒœ í™•ì¸
4. ëª¨ë“  Targetì´ `UP` ìƒíƒœì—¬ì•¼ í•¨

---

## ğŸ“Š Grafana ëŒ€ì‹œë³´ë“œ í™•ì¸

### ë©”íŠ¸ë¦­ ë°ì´í„° í™•ì¸

1. Grafana UI ì ‘ì†: http://grafana.k8s-cluster-01.miribit.lab
2. Explore ë©”ë‰´ ì„ íƒ
3. PromQL ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸:

```promql
# Spark Job ì‹¤í–‰ ìˆ˜
spark_application_running

# Kafka ë©”ì‹œì§€ ìœ ì…ìœ¨
rate(kafka_server_brokertopicmetrics_messagesin_total[5m])

# Kafka Consumer Lag
kafka_consumer_group_lag
```

### DataOps ëŒ€ì‹œë³´ë“œ í™•ì¸

1. Dashboards â†’ DataOps - Portal
2. Workload Performance Dashboard ì ‘ì†
3. Spark/Kafka ë©”íŠ¸ë¦­ íŒ¨ë„ í™•ì¸
4. Data Pipeline Dashboard ì ‘ì†
5. Kafka Pipeline ë©”íŠ¸ë¦­ í™•ì¸

---

## ğŸ§ª ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

### Spark Job ì‹¤í–‰ í…ŒìŠ¤íŠ¸

```bash
# Spark Shell ì ‘ì†
kubectl exec -it spark-master-0 -n spark -- spark-shell

# Scala ì½”ë“œ ì‹¤í–‰
scala> val data = sc.parallelize(1 to 100)
scala> data.sum()
scala> :quit
```

### Kafka Topic ìƒì„± ë° í…ŒìŠ¤íŠ¸

```bash
# Kafka Podì— ì ‘ì†
kubectl exec -it kafka-0 -n kafka -- bash

# Topic ìƒì„±
kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test-topic --partitions 3 --replication-factor 2

# Producer í…ŒìŠ¤íŠ¸
kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test-topic
> hello world
> test message
^C

# Consumer í…ŒìŠ¤íŠ¸
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### Spark Masterê°€ Runningì´ì§€ë§Œ Worker ì—°ê²° ì•ˆ ë¨

**ì¦ìƒ:**
```bash
kubectl logs spark-master-0 -n spark
# Master started but no workers connected
```

**í•´ê²°:**
```bash
# Worker ë¡œê·¸ í™•ì¸
kubectl logs spark-worker-0 -n spark

# Service í™•ì¸
kubectl get svc -n spark

# Master URL í™•ì¸
kubectl exec spark-worker-0 -n spark -- env | grep SPARK_MASTER_URL
```

### Kafka Brokerê°€ Ready ìƒíƒœê°€ ì•ˆ ë¨

**ì¦ìƒ:**
```bash
kubectl get pods -n kafka
# kafka-0   0/1   CrashLoopBackOff
```

**í•´ê²°:**
```bash
# ë¡œê·¸ í™•ì¸
kubectl logs kafka-0 -n kafka

# PVC í™•ì¸ (ìŠ¤í† ë¦¬ì§€ ë¬¸ì œ ê°€ëŠ¥ì„±)
kubectl get pvc -n kafka

# Longhorn ë³¼ë¥¨ í™•ì¸
kubectl get pv | grep kafka
```

### Prometheusì— ë©”íŠ¸ë¦­ì´ ì•ˆ ë³´ì„

**ì¦ìƒ:**
Prometheusì—ì„œ `spark_*` ë˜ëŠ” `kafka_*` ë©”íŠ¸ë¦­ì´ ì¡°íšŒë˜ì§€ ì•ŠìŒ

**í•´ê²°:**
```bash
# ServiceMonitor í™•ì¸
kubectl get servicemonitor -A

# Service Endpoints í™•ì¸
kubectl get endpoints -n spark
kubectl get endpoints -n kafka

# Prometheus Operator ë¡œê·¸
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus-operator

# ServiceMonitorì— ì˜¬ë°”ë¥¸ Labelì´ ìˆëŠ”ì§€ í™•ì¸
kubectl get servicemonitor spark-metrics -n spark -o yaml | grep -A5 labels
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### Helm Charts
- **Bitnami Spark**: https://github.com/bitnami/charts/tree/main/bitnami/spark
- **Bitnami Kafka**: https://github.com/bitnami/charts/tree/main/bitnami/kafka

### Prometheus Metrics
- **Spark Metrics**: https://spark.apache.org/docs/latest/monitoring.html
- **Kafka JMX Metrics**: https://kafka.apache.org/documentation/#monitoring

### Kustomize + Helm
- **Kustomize Helm Generator**: https://kubectl.docs.kubernetes.io/references/kustomize/builtins/#_helmchartinflationgenerator_

---

## âœ… ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Git Repositoryì— ë§¤ë‹ˆí˜ìŠ¤íŠ¸ Push
- [ ] ArgoCDì— Application ìƒì„±
- [ ] Spark ë°°í¬ ì™„ë£Œ ë° Pod Running í™•ì¸
- [ ] Kafka ë°°í¬ ì™„ë£Œ ë° Pod Running í™•ì¸
- [ ] ServiceMonitor ìƒì„± í™•ì¸
- [ ] Prometheus Targets UP ìƒíƒœ í™•ì¸
- [ ] Grafanaì—ì„œ ë©”íŠ¸ë¦­ ì¡°íšŒ í™•ì¸
- [ ] DataOps ëŒ€ì‹œë³´ë“œì—ì„œ ë°ì´í„° í‘œì‹œ í™•ì¸
- [ ] Spark Job í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] Kafka Topic ìƒì„± ë° ë©”ì‹œì§€ ì†¡ìˆ˜ì‹  í…ŒìŠ¤íŠ¸

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **Airflow ë°°í¬**: ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
2. **Trino ë°°í¬**: ë¶„ì‚° SQL ì¿¼ë¦¬ ì—”ì§„
3. **Hive Metastore ë°°í¬**: ë©”íƒ€ë°ì´í„° ê´€ë¦¬
4. **Iceberg Table ìƒì„±**: Data Lake êµ¬ì¶•
5. **End-to-End Pipeline í…ŒìŠ¤íŠ¸**: Kafka â†’ Spark â†’ Iceberg â†’ Trino

---

**ì‘ì„±ì¼**: 2025-11-07
**ì—…ë°ì´íŠ¸**: 2025-11-07
