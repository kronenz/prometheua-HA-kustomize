# ë¹…ë°ì´í„° ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ìƒíƒœ

## ğŸ“‹ ë°°í¬ ê°œìš”

**ë°°í¬ ì¼ì‹œ**: 2025-11-07
**í´ëŸ¬ìŠ¤í„°**: cluster-01-central (192.168.101.194)
**ë°°í¬ ë°©ì‹**: Helm + Kustomize

---

## âœ… Apache Spark ë°°í¬ ì™„ë£Œ

### ë°°í¬ ìƒíƒœ
- **ë„¤ì„ìŠ¤í˜ì´ìŠ¤**: `spark`
- **ë°°í¬ ë°©ì‹**: Helm Chart (bitnami/spark v10.0.3)
- **ì´ë¯¸ì§€**: `public.ecr.aws/bitnami/spark:3.5.3`
- **Pod ìƒíƒœ**: Running

### ë°°í¬ëœ ë¦¬ì†ŒìŠ¤

```bash
# Pods
NAME             READY   STATUS    RESTARTS   AGE
spark-master-0   1/1     Running   0          15m
spark-worker-0   1/1     Running   0          15m

# Services
NAME               TYPE        CLUSTER-IP       PORT(S)
spark-master-svc   ClusterIP   10.110.112.154   7077/TCP,80/TCP
spark-headless     ClusterIP   None             <none>

# ServiceMonitor
NAME            AGE
spark-metrics   15m
```

### Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘

**ServiceMonitor ì„¤ì •**:
```yaml
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: spark
      app.kubernetes.io/component: master
  endpoints:
    - port: http
      path: /metrics/prometheus
      interval: 30s
      scrapeTimeout: 10s
```

**Prometheus Target ìƒíƒœ**:
- âœ… Target Discovered: `10.0.0.136:8080`
- âœ… Target Up: `1` (ì •ìƒ)
- âœ… Job: `spark-master-svc`
- âœ… Namespace: `spark`

### ì ‘ì† ì •ë³´

```bash
# Spark Master Web UI
kubectl port-forward -n spark svc/spark-master-svc 8080:80

# ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
http://localhost:8080
```

### ì œì¶œëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜ˆì œ

```bash
# Spark-submit ì˜ˆì œ
kubectl exec -n spark spark-worker-0 -- spark-submit \
  --master spark://spark-master-svc:7077 \
  --class org.apache.spark.examples.SparkPi \
  /opt/bitnami/spark/examples/jars/spark-examples*.jar 5
```

---

## âš ï¸ Apache Kafka ë°°í¬ ë³´ë¥˜

### í˜„ì¬ ìƒíƒœ
- **ìƒíƒœ**: ë°°í¬ ë³´ë¥˜ (ë¦¬ì†ŒìŠ¤ ì œì•½ìœ¼ë¡œ ì¸í•œ ë³µì¡ì„±)
- **ì›ì¸**: ë‹¨ì¼ ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ì˜ ë¦¬ì†ŒìŠ¤ í•œê³„ ë° êµ¬ì„± ë³µì¡ì„±

### ë°œìƒí•œ ë¬¸ì œë“¤

1. **ì´ë¯¸ì§€ ê°€ìš©ì„± ë¬¸ì œ**
   - Docker Hubì˜ Bitnami ì´ë¯¸ì§€ê°€ 2025ë…„ë¶€í„° ì œí•œë¨
   - JMX Exporter ì´ë¯¸ì§€ `docker.io/bitnami/jmx-exporter:1.4.0` ì‚¬ìš© ë¶ˆê°€

2. **ë¦¬ì†ŒìŠ¤ ì œì•½**
   - 3ê°œ ë³µì œë³¸ ë°°í¬ ì‹œ CPU ë¶€ì¡± (Insufficient CPU)
   - ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° í™˜ê²½ì˜ ë¦¬ì†ŒìŠ¤ í•œê³„

3. **KRaft êµ¬ì„± ë¬¸ì œ**
   ```
   ERROR: controller.quorum.voters is not set
   Must specify: --standalone, --initial-controllers, or --no-initial-controllers
   ```

### ë°°í¬ ë³´ë¥˜ ì‚¬ìœ 

1. **ë¦¬ì†ŒìŠ¤ ì œì•½**
   - ë‹¨ì¼ ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ì—ì„œ Kafka 3-replica ê¸°ë³¸ ì„¤ì • ë¶ˆê°€
   - CPU ë¶€ì¡±ìœ¼ë¡œ ë‹¤ì¤‘ Pod ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨
   - ìµœì†Œ 1 CPU core + 1GB ë©”ëª¨ë¦¬ í•„ìš”í•˜ë‚˜ ê°€ìš© ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

2. **êµ¬ì„± ë³µì¡ì„±**
   - KRaft ë‹¨ì¼ ë…¸ë“œ ëª¨ë“œëŠ” ì¶”ê°€ í™˜ê²½ ë³€ìˆ˜ ë° quorum ì„¤ì • í•„ìš”
   - Zookeeper ëª¨ë“œëŠ” ë³„ë„ Zookeeper StatefulSet í•„ìš”
   - JMX Exporter ì´ë¯¸ì§€ ê°€ìš©ì„± ë¬¸ì œ

3. **í˜„ì‹¤ì  ëŒ€ì•ˆ**
   - Spark ë©”íŠ¸ë¦­ìœ¼ë¡œ ë¨¼ì € ëŒ€ì‹œë³´ë“œ ê²€ì¦
   - í”„ë¡œë•ì…˜ í™˜ê²½ (ë©€í‹° ë…¸ë“œ)ì—ì„œ Kafka ë°°í¬
   - ë˜ëŠ” ë³„ë„ ì „ìš© Kafka í´ëŸ¬ìŠ¤í„° êµ¬ì¶•

### í–¥í›„ ë°°í¬ ê°€ì´ë“œ

**í”„ë¡œë•ì…˜ í™˜ê²½ ê¶Œì¥ ì‚¬í•­**:
```yaml
# ìµœì†Œ 3-node í´ëŸ¬ìŠ¤í„°
controller:
  replicaCount: 3
  resources:
    requests:
      cpu: 500m
      memory: 2Gi

# Persistent storage
persistence:
  enabled: true
  storageClass: longhorn
  size: 20Gi
```

---

## ğŸ“Š í˜„ì¬ ìˆ˜ì§‘ ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­

### Kubernetes ê¸°ë³¸ ë©”íŠ¸ë¦­ (ì •ìƒ ìˆ˜ì§‘ ì¤‘)
- `kube_*` - Kubernetes ë¦¬ì†ŒìŠ¤ ìƒíƒœ
- `node_*` - ë…¸ë“œ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
- `container_*` - ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

### Spark ë©”íŠ¸ë¦­ (ServiceMonitor í™œì„±í™”)
- `up{namespace="spark"}` - Spark ì„œë¹„ìŠ¤ ìƒíƒœ
- Spark Web UI: `http://spark-master-svc:80`

### ë¯¸ìˆ˜ì§‘ ë©”íŠ¸ë¦­
- âŒ `spark_*` - Spark ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ (PrometheusServlet ë¯¸êµ¬ì„±)
- âŒ `kafka_*` - Kafka ë¯¸ë°°í¬
- âŒ `airflow_*` - Airflow ë¯¸ë°°í¬
- âŒ `trino_*` - Trino ë¯¸ë°°í¬

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### âœ… ì™„ë£Œ: Spark PrometheusServlet êµ¬ì„±
```yaml
# ì ìš©ëœ ì„¤ì •
configuration: |
  spark.metrics.conf.*.sink.prometheusServlet.class=org.apache.spark.metrics.sink.PrometheusServlet
  spark.metrics.conf.*.sink.prometheusServlet.path=/metrics/prometheus
  spark.metrics.conf.master.sink.prometheusServlet.path=/metrics/prometheus
  spark.ui.prometheus.enabled=true
```

**í˜„ì¬ Spark ë°°í¬ ìƒíƒœ**:
- Master: 1 replica (Running)
- Worker: 2 replicas (Running)
- Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™œì„±í™”

### ìš°ì„ ìˆœìœ„ 1: Grafana ëŒ€ì‹œë³´ë“œ ê²€ì¦
1. Grafanaì—ì„œ Spark ë°ì´í„°ì†ŒìŠ¤ í™•ì¸
2. DataOps ëŒ€ì‹œë³´ë“œì—ì„œ Kubernetes ë©”íŠ¸ë¦­ ì‹œê°í™” í™•ì¸
3. ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ìœ¼ë¡œ íŒ¨ë„ ì¡°ì •

### ìš°ì„ ìˆœìœ„ 2: ì‹¤ì œ Spark Job ì‹¤í–‰
```bash
# ì˜ˆì œ ì‘ì—… ì‹¤í–‰í•˜ì—¬ ë©”íŠ¸ë¦­ ìƒì„±
kubectl exec -n spark spark-worker-0 -- \
  spark-submit --master spark://spark-master-svc:7077 \
  --class org.apache.spark.examples.SparkPi \
  /opt/bitnami/spark/examples/jars/spark-examples*.jar 100
```

### ìš°ì„ ìˆœìœ„ 3: ëŒ€ì‹œë³´ë“œ PromQL ìµœì í™”
- Kubernetes ë©”íŠ¸ë¦­ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ êµ¬ì„±
- Spark ë©”íŠ¸ë¦­ ì¶”ê°€ (ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ ê¸°ë°˜)
- Kafka/Airflow/TrinoëŠ” ë³„ë„ í´ëŸ¬ìŠ¤í„° ë°°í¬ í›„ ì¶”ê°€

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### Spark Pod ì¬ì‹œì‘
```bash
kubectl delete pod -n spark spark-master-0 spark-worker-0
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=spark -n spark --timeout=120s
```

### Prometheus Target í™•ì¸
```bash
kubectl port-forward -n monitoring svc/kube-prometheus-stack-prometheus 9090:9090
# ë¸Œë¼ìš°ì €: http://localhost:9090/targets
# ê²€ìƒ‰: spark
```

### ServiceMonitor ì¬ì ìš©
```bash
kubectl delete servicemonitor -n spark spark-metrics
kubectl apply -f /tmp/spark-servicemonitor.yaml
```

### Helm Release ì •ë¦¬
```bash
# Spark ì œê±°
helm uninstall spark -n spark
kubectl delete namespace spark

# Kafka ì œê±°
helm uninstall kafka -n kafka
kubectl delete namespace kafka
kubectl delete pvc --all -n kafka
```

---

## ğŸ“ ë³€ê²½ ì‚¬í•­ ìš”ì•½

### 2025-11-07 ë°°í¬

**ì„±ê³µ í•­ëª©**:
1. âœ… Spark ë°°í¬ ì™„ë£Œ (ECR ì´ë¯¸ì§€ ì‚¬ìš©)
2. âœ… ServiceMonitor ìƒì„± ë° Prometheus í†µí•©
3. âœ… Base êµ¬ì„± íŒŒì¼ ì—…ë°ì´íŠ¸ (ECR ì´ë¯¸ì§€ë¡œ ë³€ê²½)
4. âœ… Prometheus Target ì •ìƒ ë“±ë¡

**ì‹¤íŒ¨ í•­ëª©**:
1. âŒ Kafka ë°°í¬ (KRaft êµ¬ì„± ë¬¸ì œ)
2. âŒ Spark PrometheusServlet ë©”íŠ¸ë¦­ (ì¶”ê°€ êµ¬ì„± í•„ìš”)

**ì—…ë°ì´íŠ¸ëœ íŒŒì¼**:
- `/root/develop/thanos/deploy-new/base/spark/values.yaml` - ECR ì´ë¯¸ì§€ ì‚¬ìš©
- `/root/develop/thanos/deploy-new/base/spark/kustomization.yaml` - Chart ë²„ì „ ì—…ë°ì´íŠ¸
- `/root/develop/thanos/deploy-new/base/spark/servicemonitor.yaml` - ServiceMonitor ì¶”ê°€
- `/root/develop/thanos/deploy-new/base/kafka/values.yaml` - ECR ì´ë¯¸ì§€ ì‚¬ìš© (ë°°í¬ ì‹¤íŒ¨)

---

## ğŸŒ ì°¸ê³  ìë£Œ

### Bitnami ì´ë¯¸ì§€ ë³€ê²½ ì‚¬í•­ (2025)
- [Bitnami Catalog Changes](https://github.com/bitnami/charts/issues/35164)
- 2025ë…„ 8ì›” 28ì¼ë¶€í„° ë¬´ë£Œ ì´ë¯¸ì§€ëŠ” `latest` íƒœê·¸ë§Œ ì œê³µ
- ì´ì „ ë²„ì „ì€ `docker.io/bitnamilegacy`ë¡œ ì´ë™
- **í•´ê²°ì±…**: Amazon ECR Public Gallery ì‚¬ìš© (`public.ecr.aws/bitnami/*`)

### ì‚¬ìš©ëœ ì´ë¯¸ì§€
```yaml
# Spark (ì„±ê³µ)
image: public.ecr.aws/bitnami/spark:3.5.3

# Kafka (ì‹¤íŒ¨ - KRaft êµ¬ì„± ë¬¸ì œ)
image: public.ecr.aws/bitnami/kafka:3.9.0
```

### Helm Chart ë²„ì „
- bitnami/spark: 10.0.3 (App: 4.0.0)
- bitnami/kafka: 32.4.3 (App: 4.0.0)
