# DataOps ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­ ë§¤í•‘ ê°€ì´ë“œ

## ğŸ“Š í˜„í™© ìš”ì•½

**ë°°í¬ëœ ì• í”Œë¦¬ì¼€ì´ì…˜**: Apache Sparkë§Œ ë°°í¬ë¨
**ë¯¸ë°°í¬ ì• í”Œë¦¬ì¼€ì´ì…˜**: Kafka, Airflow, Trino

**ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­**:
- âœ… Kubernetes ë©”íŠ¸ë¦­ (`kube_*`, `container_*`, `node_*`)
- âœ… Spark ë©”íŠ¸ë¦­ (`metrics_master_*`, `metrics_CodeGenerator_*`)
- âŒ Kafka ë©”íŠ¸ë¦­ (ë¯¸ë°°í¬)
- âŒ Airflow ë©”íŠ¸ë¦­ (ë¯¸ë°°í¬)
- âŒ Trino ë©”íŠ¸ë¦­ (ë¯¸ë°°í¬)

---

## ğŸ”„ ë©”íŠ¸ë¦­ ë§¤í•‘ ì „ëµ

### ì „ëµ 1: Spark ë©”íŠ¸ë¦­ìœ¼ë¡œ ëŒ€ì²´
Kafka/Airflow íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ â†’ Spark ì²˜ë¦¬ ë©”íŠ¸ë¦­ìœ¼ë¡œ ë³€ê²½

### ì „ëµ 2: Kubernetes ë©”íŠ¸ë¦­ ì‚¬ìš©
ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë° ìƒíƒœ ë©”íŠ¸ë¦­ â†’ K8s Pod/Container ë©”íŠ¸ë¦­ ì‚¬ìš©

### ì „ëµ 3: íŒ¨ë„ ë¹„í™œì„±í™”
ì™„ì „íˆ ëŒ€ì²´ ë¶ˆê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ â†’ "ë°ì´í„° ì—†ìŒ" ë˜ëŠ” ë¹„í™œì„±í™”

---

## ğŸ“‹ ìƒì„¸ ë©”íŠ¸ë¦­ ë§¤í•‘

### 1. Kafka ë©”íŠ¸ë¦­ â†’ Spark ë©”íŠ¸ë¦­

#### 1.1 Message Ingest Rate
**ì›ë³¸ (Kafka)**:
```promql
sum(rate(kafka_server_brokertopicmetrics_messagesin_total[5m]))
```

**ëŒ€ì²´ (Spark)**:
```promql
# Spark Masterì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜
metrics_master_apps_Value{namespace="spark"}

# ë˜ëŠ”: Spark Worker ìˆ˜ (ì²˜ë¦¬ capacity)
metrics_master_aliveWorkers_Value{namespace="spark"}
```

**ì„¤ëª…**:
- Kafka ë©”ì‹œì§€ ìˆ˜ì‹ ìœ¨ì„ Spark ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ìˆ˜ë¡œ ëŒ€ì²´
- "ë°ì´í„° ìœ ì…ë¥ " ëŒ€ì‹  "ì²˜ë¦¬ ìš©ëŸ‰" ê´€ì ìœ¼ë¡œ ë³€ê²½

#### 1.2 Consumer Lag
**ì›ë³¸ (Kafka)**:
```promql
sum(kafka_consumer_group_lag)
```

**ëŒ€ì²´ (Kubernetes Pod)**:
```promql
# Spark Worker Podì˜ Restart íšŸìˆ˜ (ì•ˆì •ì„± ì§€í‘œ)
sum(kube_pod_container_status_restarts_total{namespace="spark", pod=~"spark-worker.*"})

# ë˜ëŠ”: Pending/Failed Pod ìˆ˜
count(kube_pod_status_phase{namespace="spark", phase!="Running"})
```

**ì„¤ëª…**:
- Consumer Lag (ì²˜ë¦¬ ì§€ì—°) â†’ Pod ì•ˆì •ì„±ìœ¼ë¡œ ëŒ€ì²´
- ì¬ì‹œì‘ íšŸìˆ˜ê°€ ë†’ìœ¼ë©´ ì²˜ë¦¬ ë¬¸ì œ ë°œìƒ ì˜ë¯¸

#### 1.3 Topicë³„ ì²˜ë¦¬ìœ¨
**ì›ë³¸ (Kafka)**:
```promql
topk(10, sum(rate(kafka_server_brokertopicmetrics_messagesin_total[5m])) by (topic))
```

**ëŒ€ì²´ (Spark Workers)**:
```promql
# Workerë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
topk(10, rate(container_cpu_usage_seconds_total{namespace="spark", pod=~"spark-worker.*"}[5m]))
```

**ì„¤ëª…**:
- Topicë³„ ì²˜ë¦¬ìœ¨ â†’ Workerë³„ CPU ì‚¬ìš©ë¥ 
- ê° Workerì˜ ì²˜ë¦¬ ë¶€í•˜ë¥¼ ëª¨ë‹ˆí„°ë§

---

### 2. Airflow ë©”íŠ¸ë¦­ â†’ Spark/K8s ë©”íŠ¸ë¦­

#### 2.1 Task Success Rate
**ì›ë³¸ (Airflow)**:
```promql
sum(rate(airflow_dagrun_success[1h])) / sum(rate(airflow_dagrun_total[1h])) * 100
```

**ëŒ€ì²´ (Spark Job)**:
```promql
# Spark Job ì„±ê³µë¥  (ë¯¸ì œê³µ - íŒ¨ë„ ë¹„í™œì„±í™”)
# ëŒ€ì‹ : Spark Master ê°€ìš©ì„±
(metrics_master_aliveWorkers_Value{namespace="spark"} > 0) * 100
```

**ì„¤ëª…**:
- Airflow DAG ì„±ê³µë¥  â†’ Spark í´ëŸ¬ìŠ¤í„° ê°€ìš©ì„±ìœ¼ë¡œ ëŒ€ì²´
- 100% = í´ëŸ¬ìŠ¤í„° ì •ìƒ, 0% = í´ëŸ¬ìŠ¤í„° ë‹¤ìš´

#### 2.2 Task Duration (P95)
**ì›ë³¸ (Airflow)**:
```promql
histogram_quantile(0.95, sum(rate(airflow_task_duration_seconds_bucket[5m])) by (le, dag_id))
```

**ëŒ€ì²´ (Spark CodeGenerator)**:
```promql
# Spark ì½”ë“œ ìƒì„± ì‹œê°„ (P95)
metrics_CodeGenerator_compilationTime_95thPercentile{namespace="spark"}
```

**ì„¤ëª…**:
- Airflow Task ì‹¤í–‰ ì‹œê°„ â†’ Spark ì½”ë“œ ìƒì„± ì‹œê°„
- ê°„ì ‘ì ì¸ ì„±ëŠ¥ ì§€í‘œë¡œ í™œìš©

#### 2.3 Running Tasks
**ì›ë³¸ (Airflow)**:
```promql
sum(rate(airflow_task_started_total[5m])) * 60
```

**ëŒ€ì²´ (Spark Pods)**:
```promql
# ì‹¤í–‰ ì¤‘ì¸ Spark Pod ìˆ˜
count(kube_pod_status_phase{namespace="spark", phase="Running"})
```

**ì„¤ëª…**:
- ì‹¤í–‰ ì¤‘ì¸ Task ìˆ˜ â†’ ì‹¤í–‰ ì¤‘ì¸ Pod ìˆ˜
- í´ëŸ¬ìŠ¤í„° í™œë™ì„± ì§€í‘œ

---

### 3. Trino ë©”íŠ¸ë¦­ â†’ Spark ë©”íŠ¸ë¦­

#### 3.1 Query Execution Time (P95)
**ì›ë³¸ (Trino)**:
```promql
histogram_quantile(0.95, sum(rate(trino_execution_query_execution_time_seconds_bucket[5m])) by (le))
```

**ëŒ€ì²´ (Spark)**:
```promql
# Spark ì½”ë“œ ìƒì„± í‰ê·  ì‹œê°„
metrics_CodeGenerator_compilationTime_Mean{namespace="spark"}
```

**ì„¤ëª…**:
- Trino ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ â†’ Spark ë‚´ë¶€ ì²˜ë¦¬ ì‹œê°„
- SQL ì„±ëŠ¥ â†’ ì²˜ë¦¬ ì—”ì§„ ì„±ëŠ¥

#### 3.2 Running Queries
**ì›ë³¸ (Trino)**:
```promql
sum(trino_execution_query_running)
```

**ëŒ€ì²´ (Spark)**:
```promql
# ì‹¤í–‰ ì¤‘ì¸ Spark ì• í”Œë¦¬ì¼€ì´ì…˜
metrics_master_apps_Value{namespace="spark"}
```

**ì„¤ëª…**:
- ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ â†’ ì‹¤í–‰ ì¤‘ì¸ Spark ì•±

---

### 4. Spark ë©”íŠ¸ë¦­ (ì‚¬ìš© ê°€ëŠ¥)

#### 4.1 Spark Application Running
**ì›ë³¸ (ëŒ€ì‹œë³´ë“œ)**:
```promql
spark_application_running_jobs
```

**ìˆ˜ì • (ì‹¤ì œ ë©”íŠ¸ë¦­)**:
```promql
# Spark Masterì—ì„œ ê´€ë¦¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜
metrics_master_apps_Value{namespace="spark"}
```

#### 4.2 Spark Worker Status
**ì›ë³¸ (ëŒ€ì‹œë³´ë“œ)**:
```promql
sum(spark_executor_memory_used_bytes)
```

**ìˆ˜ì • (ì‹¤ì œ ë©”íŠ¸ë¦­)**:
```promql
# Spark Worker ê°€ìš©ì„±
metrics_master_aliveWorkers_Value{namespace="spark"}

# ë˜ëŠ”: Container ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
sum(container_memory_working_set_bytes{namespace="spark", pod=~"spark-worker.*"})
```

---

## ğŸ¨ ëŒ€ì‹œë³´ë“œë³„ ìˆ˜ì • ê³„íš

### 05-data-pipeline.yaml

**ìˆ˜ì • í•„ìš” íŒ¨ë„**:
1. **Kafka Message Ingest Rate** â†’ **Spark Cluster Capacity**
   ```promql
   metrics_master_aliveWorkers_Value{namespace="spark"}
   ```

2. **Kafka Consumer Lag** â†’ **Spark Pod Restarts**
   ```promql
   sum(kube_pod_container_status_restarts_total{namespace="spark"})
   ```

3. **Data Quality Score** â†’ **Spark Cluster Health**
   ```promql
   (count(kube_pod_status_phase{namespace="spark", phase="Running"}) / count(kube_pod_info{namespace="spark"})) * 100
   ```

### 01-deployment-pipeline.yaml

**ìˆ˜ì • í•„ìš” íŒ¨ë„**:
1. **Airflow DAG Success Rate** â†’ **Spark Cluster Uptime**
   ```promql
   (metrics_master_aliveWorkers_Value{namespace="spark"} > 0) * 100
   ```

2. **Airflow Task Duration** â†’ **Spark Processing Time**
   ```promql
   metrics_CodeGenerator_compilationTime_Mean{namespace="spark"}
   ```

### 04-workload-performance.yaml

**ìˆ˜ì • í•„ìš” íŒ¨ë„**:
1. **Spark Application Running** â†’ ìˆ˜ì •
   ```promql
   metrics_master_apps_Value{namespace="spark"}
   ```

2. **Spark Executor Memory** â†’ ìˆ˜ì •
   ```promql
   sum(container_memory_working_set_bytes{namespace="spark", pod=~"spark-worker.*"}) / 1024 / 1024
   ```

---

## ğŸ”§ PromQL ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸

### ì¼ê´„ ìˆ˜ì • ëª…ë ¹ì–´

```bash
# 1. Kafka ë©”íŠ¸ë¦­ â†’ Spark ë©”íŠ¸ë¦­
find /root/develop/thanos/deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops-v4 -name "*.yaml" -type f -exec \
  sed -i 's|kafka_server_brokertopicmetrics_messagesin_total|metrics_master_aliveWorkers_Value{namespace=\"spark\"}|g' {} \;

# 2. Kafka Consumer Lag â†’ Spark Pod Restarts
find /root/develop/thanos/deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops-v4 -name "*.yaml" -type f -exec \
  sed -i 's|kafka_consumer_group_lag|kube_pod_container_status_restarts_total{namespace=\"spark\"}|g' {} \;

# 3. Airflow DAG â†’ Spark Cluster
find /root/develop/thanos/deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops-v4 -name "*.yaml" -type f -exec \
  sed -i 's|airflow_dagrun_success|metrics_master_aliveWorkers_Value{namespace=\"spark\"}|g' {} \;
```

---

## ğŸ“Š ìµœì¢… ëŒ€ì‹œë³´ë“œ êµ¬ì„±

### ì‚¬ìš© ê°€ëŠ¥í•œ íŒ¨ë„
âœ… Spark í´ëŸ¬ìŠ¤í„° ìƒíƒœ
âœ… Spark Worker ê°€ìš©ì„±
âœ… Spark ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜
âœ… Spark ì½”ë“œ ìƒì„± ì„±ëŠ¥
âœ… Kubernetes Pod ìƒíƒœ
âœ… Container ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
âœ… Node ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

### ë¹„í™œì„±í™” ë˜ëŠ” ëŒ€ì²´ í•„ìš”
âš ï¸ Kafka ë©”íŠ¸ë¦­ â†’ Sparkë¡œ ëŒ€ì²´
âš ï¸ Airflow ë©”íŠ¸ë¦­ â†’ K8së¡œ ëŒ€ì²´
âš ï¸ Trino ë©”íŠ¸ë¦­ â†’ Sparkë¡œ ëŒ€ì²´
âŒ Iceberg ë©”íŠ¸ë¦­ â†’ ë¹„í™œì„±í™”

---

## ğŸš€ ë°°í¬ ì ˆì°¨

### 1. ë°±ì—…
```bash
cp -r /root/develop/thanos/deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops-v4 \
   /root/develop/thanos/deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops-v4.backup
```

### 2. ìˆ˜ì • ì ìš©
```bash
# Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì •ë°€ ìˆ˜ì • (ê¶Œì¥)
python3 /root/develop/thanos/scripts/update-dashboard-metrics.py
```

### 3. ConfigMap ì¬ë°°í¬
```bash
kubectl apply -k /root/develop/thanos/deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops-v4/
```

### 4. Grafana ì¬ì‹œì‘ (ì„ íƒ)
```bash
kubectl rollout restart deployment -n monitoring kube-prometheus-stack-grafana
```

---

## ğŸ” ê²€ì¦ ë°©ë²•

### Prometheusì—ì„œ ë©”íŠ¸ë¦­ í™•ì¸
```bash
# Spark ë©”íŠ¸ë¦­ ì¿¼ë¦¬
kubectl --context cluster-01 exec -n monitoring prometheus-kube-prometheus-stack-prometheus-0 -- \
  wget -qO- "http://localhost:9090/api/v1/query?query=metrics_master_aliveWorkers_Value"

# Container ë©”íŠ¸ë¦­ ì¿¼ë¦¬
kubectl --context cluster-01 exec -n monitoring prometheus-kube-prometheus-stack-prometheus-0 -- \
  wget -qO- "http://localhost:9090/api/v1/query?query=container_memory_working_set_bytes{namespace=\"spark\"}"
```

### Grafanaì—ì„œ ëŒ€ì‹œë³´ë“œ í™•ì¸
1. http://grafana.k8s-cluster-01.miribit.lab ì ‘ì†
2. DataOps í¬í„¸ ëŒ€ì‹œë³´ë“œ ì—´ê¸°
3. ê° íŒ¨ë„ì˜ ë°ì´í„° í‘œì‹œ ì—¬ë¶€ í™•ì¸
4. "No data" íŒ¨ë„ í™•ì¸ ë° PromQL ê²€ì¦

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Spark ë©”íŠ¸ë¦­ ê°€ì´ë“œ](./03-ë©”íŠ¸ë¦­-ê°€ì´ë“œ.md)
- [Prometheus PromQL ë¬¸ì„œ](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Kubernetes ë©”íŠ¸ë¦­](https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/)
