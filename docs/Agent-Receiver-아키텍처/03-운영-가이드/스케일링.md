# 스케일링

## 📋 개요

Prometheus Agent + Thanos Receiver 환경의 수평/수직 스케일링 전략과 실행 방법을 다룹니다.

---

## 🎯 스케일링 목표

- **성능**: 샘플 처리량 2배 증가 시 1시간 내 스케일 아웃
- **비용**: 리소스 활용률 70-80% 유지
- **가용성**: 스케일링 중 서비스 무중단
- **자동화**: HPA/VPA로 자동 스케일링

---

## 1️⃣ 스케일링 의사결정

### 스케일 아웃 트리거

| 메트릭 | 임계값 | 조치 |
|--------|--------|------|
| **Remote Write Queue** | > 5000 (15분) | Agent 샤드 증가 또는 Receiver 증설 |
| **Receiver CPU** | > 80% (10분) | Receiver 수평 확장 |
| **Receiver Memory** | > 85% (10분) | Receiver 수직 확장 |
| **TSDB 용량** | > 70% | PVC 확장 또는 Retention 단축 |
| **샘플 처리 지연** | > 2초 (p99) | Receiver 증설 |

### 스케일 인 트리거

| 메트릭 | 임계값 | 조치 |
|--------|--------|------|
| **Receiver CPU** | < 30% (1시간) | Receiver 축소 (최소 3개 유지) |
| **Receiver Memory** | < 40% (1시간) | Receiver 메모리 축소 |
| **Remote Write Queue** | = 0 (30분) | Agent 샤드 감소 |

---

## 2️⃣ Prometheus Agent 스케일링

### Remote Write Shards 자동 조정

```yaml
# Agent가 자동으로 Shards 조정 (기본 동작)
prometheus:
  prometheusSpec:
    remoteWrite:
      - url: http://thanos-receive-lb:19291/api/v1/receive
        queueConfig:
          minShards: 10      # 최소 Shards
          maxShards: 100     # 최대 Shards (자동 조정)
          capacity: 20000
```

### Shards 수동 조정 (긴급)

```promql
# 현재 Shards 확인
prometheus_remote_storage_shards{cluster="cluster-03"}

# 출력: 50 (동적 조정 중)
```

```bash
# Agent 재시작으로 Shards 재계산
kubectl rollout restart statefulset/prometheus-agent -n monitoring
```

### Agent Scrape 간격 조정 (부하 감소)

```yaml
# Scrape Interval 증가 (30s → 60s)
prometheus:
  prometheusSpec:
    scrapeInterval: 60s     # 샘플 수 50% 감소
    scrapeTimeout: 15s
```

---

## 3️⃣ Thanos Receiver 수평 확장

### Receiver Replicas 증가

```yaml
# StatefulSet Replicas 변경
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: thanos-receive
  namespace: monitoring
spec:
  replicas: 5  # 3 → 5로 증가
```

```bash
# Kubectl로 Scale Out
kubectl scale statefulset/thanos-receive --replicas=5 -n monitoring

# Scale Out 진행 확인
kubectl get pods -n monitoring -l app=thanos-receive -w

# 출력:
# thanos-receive-3   0/1   Pending
# thanos-receive-3   0/1   ContainerCreating
# thanos-receive-3   1/1   Running
# thanos-receive-4   0/1   Pending
# thanos-receive-4   1/1   Running
```

### Hashring 자동 업데이트 (HeadlessService 사용)

```yaml
# Receiver가 HeadlessService DNS로 자동 발견
# ConfigMap 업데이트 불필요 (SRV 레코드 사용)

# StatefulSet + HeadlessService 구성
apiVersion: v1
kind: Service
metadata:
  name: thanos-receive
  namespace: monitoring
spec:
  clusterIP: None  # Headless
  ports:
  - name: grpc
    port: 10901
  - name: http
    port: 10902
  - name: remote-write
    port: 19291
  selector:
    app: thanos-receive
```

### Hashring 수동 업데이트 (Explicit Endpoints)

```yaml
# ConfigMap에 새 Endpoint 추가
apiVersion: v1
kind: ConfigMap
metadata:
  name: thanos-receive-hashring
  namespace: monitoring
data:
  hashrings.json: |
    [
      {
        "hashring": "default",
        "endpoints": [
          "thanos-receive-0.thanos-receive.monitoring.svc.cluster.local:10901",
          "thanos-receive-1.thanos-receive.monitoring.svc.cluster.local:10901",
          "thanos-receive-2.thanos-receive.monitoring.svc.cluster.local:10901",
          "thanos-receive-3.thanos-receive.monitoring.svc.cluster.local:10901",  # 추가
          "thanos-receive-4.thanos-receive.monitoring.svc.cluster.local:10901"   # 추가
        ]
      }
    ]
```

```bash
# ConfigMap 적용
kubectl apply -f thanos-receive-hashring.yaml

# Receiver 순차 재시작 (Hot Reload 미지원)
kubectl rollout restart statefulset/thanos-receive -n monitoring

# 재시작 완료 대기
kubectl rollout status statefulset/thanos-receive -n monitoring

# Hashring 검증
kubectl logs -n monitoring thanos-receive-0 | grep "hashring"

# 로그 예시:
# level=info msg="loaded hashring configuration" endpoints=5
```

---

## 4️⃣ Thanos Receiver 수직 확장

### CPU/Memory 증가

```yaml
# Resources 수정
spec:
  template:
    spec:
      containers:
      - name: thanos-receive
        resources:
          requests:
            cpu: 2000m      # 1000m → 2000m
            memory: 4Gi     # 2Gi → 4Gi
          limits:
            cpu: 4000m
            memory: 8Gi
```

```bash
# 적용 (순차 재시작)
kubectl apply -f thanos-receiver.yaml

# Pod 재시작 확인
kubectl get pods -n monitoring -l app=thanos-receive -w

# 출력:
# thanos-receive-2   1/1   Terminating
# thanos-receive-2   0/1   Pending
# thanos-receive-2   1/1   Running  (새 리소스)
# thanos-receive-1   1/1   Terminating
# ...
```

### PVC 용량 확장

```bash
# PVC 용량 확인
kubectl get pvc -n monitoring | grep thanos-receive

# 출력:
# data-thanos-receive-0   Bound   100Gi   longhorn

# PVC 확장 (Longhorn은 온라인 확장 지원)
kubectl patch pvc data-thanos-receive-0 -n monitoring \
  -p '{"spec":{"resources":{"requests":{"storage":"200Gi"}}}}'

# 확장 확인
kubectl get pvc -n monitoring data-thanos-receive-0

# 출력:
# CAPACITY   STATUS
# 200Gi      Bound    (확장됨)

# Pod 내부 확인
kubectl exec -it -n monitoring thanos-receive-0 -- df -h /data

# 출력:
# Filesystem      Size  Used Avail Use% Mounted on
# /dev/longhorn   200G  65G  135G  33%  /data
```

---

## 5️⃣ Prometheus HA Replicas 증가

### Prometheus StatefulSet Replicas

```yaml
# kube-prometheus-stack values.yaml
prometheus:
  prometheusSpec:
    replicas: 3  # 2 → 3으로 증가

    # Replication Factor (Thanos Sidecar)
    thanos:
      objectStorageConfig:
        key: objstore.yml
        name: thanos-objstore-secret
```

```bash
# Helm Upgrade
helm upgrade kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring \
  -f values.yaml

# 또는 Kustomize
kustomize build deploy/overlays/cluster-01-central/kube-prometheus-stack --enable-helm \
  | kubectl apply -f -

# Replicas 확인
kubectl get statefulset -n monitoring prometheus-kube-prometheus-stack-prometheus

# 출력:
# NAME                                      READY   AGE
# prometheus-kube-prometheus-stack-prometheus   3/3     5d

# Prometheus Pod 목록
kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus

# 출력:
# prometheus-kube-prometheus-stack-prometheus-0   3/3   Running
# prometheus-kube-prometheus-stack-prometheus-1   3/3   Running
# prometheus-kube-prometheus-stack-prometheus-2   3/3   Running  (새 Pod)
```

### Thanos Query 중복 제거 확인

```promql
# Replica 레이블로 중복 제거
up{job="prometheus", cluster="cluster-01"}

# 출력 (Thanos Query에서):
# up{job="prometheus", cluster="cluster-01"} 1  (중복 제거됨)

# 실제 메트릭 (Prometheus 직접 쿼리):
# up{job="prometheus", replica="prometheus-0"} 1
# up{job="prometheus", replica="prometheus-1"} 1
# up{job="prometheus", replica="prometheus-2"} 1  (중복)
```

---

## 6️⃣ HPA (Horizontal Pod Autoscaler)

### Receiver HPA 설정

```yaml
# HPA: CPU 기반 자동 스케일링
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: thanos-receive-hpa
  namespace: monitoring
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: thanos-receive
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # 70% 초과 시 Scale Out

  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75

  # Custom Metric: Remote Write Queue
  - type: Pods
    pods:
      metric:
        name: prometheus_remote_storage_queue_length
      target:
        type: AverageValue
        averageValue: "3000"  # Queue > 3000 시 Scale Out

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 300  # 5분 안정화
      policies:
      - type: Percent
        value: 50  # 50%씩 증가
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 600  # 10분 안정화
      policies:
      - type: Pods
        value: 1  # 1개씩 감소
        periodSeconds: 300
```

```bash
# HPA 생성
kubectl apply -f thanos-receive-hpa.yaml

# HPA 상태 확인
kubectl get hpa -n monitoring thanos-receive-hpa

# 출력:
# NAME                  REFERENCE                 TARGETS              MINPODS   MAXPODS   REPLICAS
# thanos-receive-hpa    StatefulSet/thanos-receive   65%/70%, 60%/75%     3         10        3

# HPA 이벤트 확인
kubectl describe hpa -n monitoring thanos-receive-hpa

# 출력:
# Events:
#   Type    Reason             Message
#   ----    ------             -------
#   Normal  SuccessfulRescale  New size: 5; reason: cpu resource utilization above target
```

---

## 7️⃣ VPA (Vertical Pod Autoscaler)

### VPA 설치

```bash
# VPA Controller 설치
git clone https://github.com/kubernetes/autoscaler.git
cd autoscaler/vertical-pod-autoscaler
./hack/vpa-up.sh
```

### Receiver VPA 설정

```yaml
# VPA: 리소스 자동 조정
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: thanos-receive-vpa
  namespace: monitoring
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: thanos-receive

  updatePolicy:
    updateMode: "Auto"  # Auto, Recreate, Initial, Off

  resourcePolicy:
    containerPolicies:
    - containerName: thanos-receive
      minAllowed:
        cpu: 500m
        memory: 1Gi
      maxAllowed:
        cpu: 4000m
        memory: 8Gi
      controlledResources:
      - cpu
      - memory
```

```bash
# VPA 생성
kubectl apply -f thanos-receive-vpa.yaml

# VPA 권장사항 확인
kubectl describe vpa -n monitoring thanos-receive-vpa

# 출력:
# Recommendation:
#   Container Recommendations:
#     Container Name:  thanos-receive
#     Lower Bound:
#       Cpu:     1200m
#       Memory:  2.5Gi
#     Target:
#       Cpu:     1500m
#       Memory:  3Gi
#     Upper Bound:
#       Cpu:     2000m
#       Memory:  4Gi
```

---

## 8️⃣ 스케일링 시나리오

### 시나리오 1: 트래픽 2배 증가

**현재 상태**:
- Agent 3개 (cluster-02/03/04)
- 샘플: 8,000 samples/s
- Receiver 3 replicas

**예상 변화**:
- Agent 3개 (변경 없음)
- 샘플: 16,000 samples/s
- Receiver 필요: 5-6 replicas

**실행 계획**:

```bash
# 1. Remote Write Queue 모니터링
watch kubectl get pods -n monitoring -l app=thanos-receive \
  -o custom-columns=NAME:.metadata.name,CPU:.spec.containers[0].resources.requests.cpu,MEMORY:.spec.containers[0].resources.requests.memory

# 2. Receiver Scale Out (5 replicas)
kubectl scale statefulset/thanos-receive --replicas=5 -n monitoring

# 3. Hashring 업데이트 (자동 또는 수동)
kubectl apply -f thanos-receive-hashring.yaml
kubectl rollout restart statefulset/thanos-receive -n monitoring

# 4. 검증
kubectl top pods -n monitoring -l app=thanos-receive
```

### 시나리오 2: 새 클러스터 추가

**현재 상태**:
- 4개 클러스터 (cluster-01/02/03/04)

**목표**:
- 5개 클러스터 (cluster-05 추가)

**실행 계획**:

```bash
# 1. Receiver 용량 확인
kubectl top pods -n monitoring -l app=thanos-receive

# 2. 필요 시 Receiver Scale Out
kubectl scale statefulset/thanos-receive --replicas=4 -n monitoring

# 3. Cluster-05 Agent 배포
export KUBECONFIG=~/.kube/configs/cluster-05.conf
kustomize build deploy/overlays/cluster-05-edge/prometheus-agent --enable-helm \
  | kubectl apply -f -

# 4. Remote Write 연결 확인
kubectl logs -n monitoring prometheus-agent-0 | grep "remote write"
```

---

## 9️⃣ 비용 최적화

### 리소스 Right-Sizing

```promql
# Agent 실제 CPU 사용량
avg_over_time(rate(container_cpu_usage_seconds_total{pod=~"prometheus-agent.*"}[5m])[7d:])

# 출력: 0.18 (180m) → requests를 200m으로 조정

# Agent 실제 메모리 사용량
avg_over_time(container_memory_usage_bytes{pod=~"prometheus-agent.*"}[7d:]) / 1024 / 1024

# 출력: 280 (280Mi) → requests를 300Mi로 조정
```

### 불필요한 Replicas 축소

```bash
# Receiver CPU 사용률 확인 (7일 평균)
# PromQL: avg_over_time(rate(container_cpu_usage_seconds_total{pod=~"thanos-receive.*"}[5m])[7d:])

# 출력: 0.35 (35%) → Scale In 가능

# Receiver 축소 (5 → 3)
kubectl scale statefulset/thanos-receive --replicas=3 -n monitoring

# 비용 절감: 2 replicas * $0.05/hour * 730h = $73/month
```

### Spot Instance 활용 (Cloud)

```yaml
# Node Affinity: Spot Instance 선호
prometheus:
  prometheusSpec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          preference:
            matchExpressions:
            - key: node.kubernetes.io/instance-type
              operator: In
              values:
              - spot  # Spot Instance 우선
```

---

## 🎯 스케일링 체크리스트

### Scale Out 전
- [x] 현재 리소스 사용률 확인 (CPU, Memory)
- [x] Remote Write Queue 상태 확인
- [x] PVC 용량 확인
- [x] 스케일 아웃 필요성 검증

### Scale Out 중
- [x] Replicas 증가 (Kubectl 또는 Helm)
- [x] Hashring ConfigMap 업데이트
- [x] Pod 재시작 및 상태 확인
- [x] 서비스 연속성 확인

### Scale Out 후
- [x] 리소스 사용률 재확인 (70-80% 목표)
- [x] Remote Write 성공률 확인
- [x] 메트릭 쿼리 테스트
- [x] Alert Rule 업데이트 (임계값 조정)

---

## 🔗 관련 문서

- **Receiver 관리** → [Receiver-관리.md](./Receiver-관리.md)
- **Agent 관리** → [Agent-관리.md](./Agent-관리.md)
- **성능 최적화** → [../09-성능-최적화/README.md](../09-성능-최적화/README.md)

---

**최종 업데이트**: 2025-10-20
