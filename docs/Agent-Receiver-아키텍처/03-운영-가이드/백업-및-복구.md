# 백업 및 복구

## 📋 개요

Prometheus Agent + Thanos Receiver 환경의 데이터 백업 전략과 재해 복구 절차를 다룹니다.

---

## 🎯 백업 목표

- **RTO (Recovery Time Objective)**: 1시간 이내
- **RPO (Recovery Point Objective)**: 15분 이내
- **백업 주기**: 일일 (S3 자동), 주간 (Longhorn Snapshot)
- **보존 기간**: 30일 (백업), 7일 (Snapshot)
- **백업 위치**: MinIO S3 (Primary), Longhorn (Secondary)

---

## 1️⃣ 백업 대상

### 백업 우선순위

| 컴포넌트 | 우선순위 | 백업 방법 | RPO | RTO |
|---------|---------|----------|-----|-----|
| **S3 TSDB 블록** | P1 (Critical) | MinIO Replication | 0분 | 15분 |
| **Prometheus TSDB** | P2 (High) | Longhorn Snapshot | 15분 | 30분 |
| **ConfigMap/Secret** | P2 (High) | Git + Velero | 1일 | 15분 |
| **Grafana 대시보드** | P3 (Medium) | Git + DB Backup | 1일 | 1시간 |
| **OpenSearch 로그** | P4 (Low) | S3 Snapshot | 1일 | 2시간 |

---

## 2️⃣ S3 백업 (TSDB 블록)

### MinIO Bucket Replication

```bash
# MinIO Replication 설정 (Primary → Backup Site)
mc admin bucket remote add minio/thanos-cluster-01 \
  https://s3-backup.miribit.lab/thanos-cluster-01-backup \
  --service replication \
  --access-key backup-access-key \
  --secret-key backup-secret-key

# Replication Rule 추가
mc replicate add minio/thanos-cluster-01 \
  --remote-bucket thanos-cluster-01-backup \
  --replicate "delete,delete-marker,existing-objects"

# Replication 상태 확인
mc replicate status minio/thanos-cluster-01

# 출력:
# Replication Status: Enabled
# Remote Target: s3-backup.miribit.lab/thanos-cluster-01-backup
# Rule: Replicate all objects
# Status: Active
```

### S3 수동 백업 (mc mirror)

```bash
# 전체 버킷 백업
mc mirror minio/thanos-cluster-01 minio-backup/thanos-cluster-01-backup

# 출력:
# ...thanos/01HJXXX.../meta.json:  1.2MiB / 1.2MiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100%
# ...thanos/01HJXXX.../index:      64KiB / 64KiB  ━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100%

# 증분 백업 (변경된 파일만)
mc mirror --watch minio/thanos-cluster-01 minio-backup/thanos-cluster-01-backup

# 백업 검증
mc ls --recursive minio-backup/thanos-cluster-01-backup | wc -l

# 출력: 2500 (파일 수)
```

### S3 백업 자동화

```yaml
# CronJob: S3 Backup
apiVersion: batch/v1
kind: CronJob
metadata:
  name: s3-backup
  namespace: monitoring
spec:
  schedule: "0 2 * * *"  # 매일 오전 2시
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mc-backup
            image: minio/mc:latest
            command:
            - /bin/sh
            - -c
            - |
              mc alias set minio http://s3.minio.miribit.lab:9000 $ACCESS_KEY $SECRET_KEY
              mc alias set backup http://s3-backup.miribit.lab:9000 $BACKUP_ACCESS_KEY $BACKUP_SECRET_KEY
              mc mirror minio/thanos-cluster-01 backup/thanos-cluster-01-backup
              echo "Backup completed at $(date)"
            env:
            - name: ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: access-key
            - name: SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: secret-key
            - name: BACKUP_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-backup-credentials
                  key: access-key
            - name: BACKUP_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-backup-credentials
                  key: secret-key
          restartPolicy: OnFailure
```

---

## 3️⃣ Prometheus TSDB 백업 (Longhorn Snapshot)

### Longhorn Snapshot 생성

```yaml
# VolumeSnapshot 생성
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: prometheus-snapshot-20251020
  namespace: monitoring
spec:
  volumeSnapshotClassName: longhorn-snapshot
  source:
    persistentVolumeClaimName: prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0
```

```bash
# Snapshot 생성
kubectl apply -f prometheus-snapshot.yaml

# Snapshot 상태 확인
kubectl get volumesnapshot -n monitoring

# 출력:
# NAME                          READYTOUSE   SOURCEPVC                     AGE
# prometheus-snapshot-20251020  true         prometheus-...-prometheus-0   1m

# Snapshot 상세
kubectl describe volumesnapshot -n monitoring prometheus-snapshot-20251020
```

### 자동 Snapshot (CronJob)

```yaml
# CronJob: Longhorn Snapshot
apiVersion: batch/v1
kind: CronJob
metadata:
  name: prometheus-snapshot
  namespace: monitoring
spec:
  schedule: "0 */6 * * *"  # 6시간마다
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: snapshot-creator
          containers:
          - name: kubectl
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              SNAPSHOT_NAME="prometheus-snapshot-$(date +%Y%m%d-%H%M%S)"
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: $SNAPSHOT_NAME
                namespace: monitoring
              spec:
                volumeSnapshotClassName: longhorn-snapshot
                source:
                  persistentVolumeClaimName: prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0
              EOF
              echo "Snapshot created: $SNAPSHOT_NAME"
          restartPolicy: OnFailure
```

### Snapshot 보존 정책

```yaml
# RecurringJob (Longhorn)
apiVersion: longhorn.io/v1beta2
kind: RecurringJob
metadata:
  name: prometheus-snapshot-daily
  namespace: longhorn-system
spec:
  cron: "0 2 * * *"
  task: "snapshot"
  groups:
    - prometheus
  retain: 7  # 7일 보존
  concurrency: 2
  labels:
    backup: "daily"
```

---

## 4️⃣ ConfigMap/Secret 백업

### Velero 백업

```bash
# Velero 설치
velero install \
  --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.8.0 \
  --bucket velero-backup \
  --secret-file ./velero-credentials \
  --backup-location-config region=us-east-1,s3ForcePathStyle="true",s3Url=http://s3.minio.miribit.lab:9000 \
  --snapshot-location-config region=us-east-1

# Backup 생성 (monitoring namespace)
velero backup create monitoring-backup-$(date +%Y%m%d) \
  --include-namespaces monitoring \
  --include-resources configmaps,secrets

# Backup 상태 확인
velero backup describe monitoring-backup-20251020

# Backup 목록
velero backup get

# 출력:
# NAME                        STATUS      CREATED                  EXPIRES
# monitoring-backup-20251020  Completed   2025-10-20 02:00:00 KST  29d
```

### Git 백업 (GitOps)

```bash
# ConfigMap/Secret을 Git에 백업
kubectl get cm,secret -n monitoring -o yaml > backup/monitoring-resources-$(date +%Y%m%d).yaml

# Git Commit
git add backup/
git commit -m "backup: ConfigMaps and Secrets $(date +%Y%m%d)"
git push origin main

# 백업 검증
git log --oneline | head -5
```

---

## 5️⃣ Grafana 대시보드 백업

### Grafana Database 백업

```bash
# Grafana Pod 확인
kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana

# PostgreSQL 백업 (Grafana DB)
kubectl exec -it -n monitoring grafana-xxx -- pg_dump grafana > grafana-backup-$(date +%Y%m%d).sql

# 또는 SQLite 백업 (기본 설정)
kubectl cp -n monitoring grafana-xxx:/var/lib/grafana/grafana.db ./grafana-backup-$(date +%Y%m%d).db
```

### Dashboard JSON 백업 (API)

```bash
# Grafana API로 대시보드 Export
GRAFANA_URL="http://grafana.k8s-cluster-01.miribit.lab"
API_KEY="your-grafana-api-key"

# 모든 대시보드 목록
curl -s -H "Authorization: Bearer $API_KEY" \
  "$GRAFANA_URL/api/search?type=dash-db" | jq -r '.[].uid' > dashboard-uids.txt

# 각 대시보드 JSON 백업
while read uid; do
  curl -s -H "Authorization: Bearer $API_KEY" \
    "$GRAFANA_URL/api/dashboards/uid/$uid" | jq .dashboard \
    > "backup/grafana-dashboard-$uid.json"
done < dashboard-uids.txt

echo "Backed up $(wc -l < dashboard-uids.txt) dashboards"
```

---

## 6️⃣ OpenSearch 백업

### OpenSearch Snapshot Repository 설정

```bash
# S3 Snapshot Repository 생성
curl -X PUT "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup" \
  -H 'Content-Type: application/json' \
  -d '{
    "type": "s3",
    "settings": {
      "bucket": "opensearch-backup",
      "region": "us-east-1",
      "endpoint": "http://s3.minio.miribit.lab:9000",
      "path_style_access": true,
      "compress": true
    }
  }'

# Repository 확인
curl -X GET "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup"
```

### Snapshot 생성

```bash
# 모든 인덱스 Snapshot
curl -X PUT "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup/snapshot-$(date +%Y%m%d)" \
  -H 'Content-Type: application/json' \
  -d '{
    "indices": "*",
    "ignore_unavailable": true,
    "include_global_state": false
  }'

# Snapshot 상태 확인
curl -X GET "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup/snapshot-20251020"
```

---

## 7️⃣ 복구 절차

### S3 TSDB 블록 복구

```bash
# 백업 버킷에서 복원
mc mirror minio-backup/thanos-cluster-01-backup minio/thanos-cluster-01

# Thanos Store 재시작 (새 블록 인식)
kubectl rollout restart deployment/thanos-store -n monitoring

# 복구 검증
mc ls --recursive minio/thanos-cluster-01 | grep "meta.json" | wc -l

# Thanos Query에서 확인
curl "http://thanos-query:9090/api/v1/query?query=up" | jq .
```

### Prometheus TSDB 복구 (Longhorn Snapshot)

```yaml
# Snapshot에서 새 PVC 생성
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-db-restored
  namespace: monitoring
spec:
  storageClassName: longhorn
  dataSource:
    name: prometheus-snapshot-20251020
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
```

```bash
# PVC 생성
kubectl apply -f prometheus-pvc-restored.yaml

# Prometheus StatefulSet 수정 (새 PVC 사용)
kubectl edit statefulset prometheus-kube-prometheus-stack-prometheus -n monitoring

# volumeClaimTemplates 변경:
# - metadata:
#     name: prometheus-db-restored

# StatefulSet 재시작
kubectl rollout restart statefulset/prometheus-kube-prometheus-stack-prometheus -n monitoring
```

### ConfigMap/Secret 복구 (Velero)

```bash
# Backup 목록 확인
velero backup get

# 특정 Backup 복원
velero restore create --from-backup monitoring-backup-20251020

# 복원 상태 확인
velero restore describe monitoring-backup-20251020-restore

# 복원 로그
velero restore logs monitoring-backup-20251020-restore
```

### Grafana 대시보드 복구

```bash
# Database 복원 (PostgreSQL)
kubectl cp grafana-backup-20251020.sql monitoring/grafana-xxx:/tmp/
kubectl exec -it -n monitoring grafana-xxx -- psql grafana < /tmp/grafana-backup-20251020.sql

# Dashboard JSON 복구 (API)
for file in backup/grafana-dashboard-*.json; do
  curl -X POST "http://grafana:3000/api/dashboards/db" \
    -H "Authorization: Bearer $API_KEY" \
    -H "Content-Type: application/json" \
    -d @$file
done

# Grafana 재시작
kubectl rollout restart deployment/grafana -n monitoring
```

### OpenSearch 복구

```bash
# Snapshot 목록 확인
curl -X GET "http://opensearch:9200/_snapshot/s3_backup/_all"

# 특정 Snapshot 복원
curl -X POST "http://opensearch:9200/_snapshot/s3_backup/snapshot-20251020/_restore" \
  -H 'Content-Type: application/json' \
  -d '{
    "indices": "*",
    "ignore_unavailable": true,
    "include_global_state": false
  }'

# 복원 상태 확인
curl -X GET "http://opensearch:9200/_recovery"
```

---

## 8️⃣ 재해 복구 시나리오

### 시나리오 1: Prometheus Agent 데이터 손실

**상황**: Agent WAL 손상

**복구 절차**:
1. Agent Pod 재시작 (WAL 자동 복구)
2. Remote Write Queue 확인
3. 메트릭 연속성 검증

**RTO**: 5분
**RPO**: 0분 (Remote Write로 이미 전송됨)

```bash
# 1. Pod 재시작
kubectl delete pod -n monitoring prometheus-agent-0

# 2. Remote Write 확인
kubectl logs -n monitoring prometheus-agent-0 | grep "remote write"

# 3. 메트릭 쿼리
curl "http://thanos-query:9090/api/v1/query?query=up{cluster=\"cluster-03\"}"
```

### 시나리오 2: Thanos Receiver 전체 손실

**상황**: Receiver StatefulSet 전체 삭제

**복구 절차**:
1. S3에서 TSDB 블록 확인 (백업 존재)
2. Receiver StatefulSet 재배포
3. Store Gateway에서 S3 블록 조회

**RTO**: 15분
**RPO**: 0분 (S3에 자동 업로드됨)

```bash
# 1. S3 블록 확인
mc ls --recursive minio/thanos-cluster-01 | grep meta.json | wc -l

# 2. Receiver 재배포
kubectl apply -f thanos-receiver.yaml

# 3. Store Gateway 재시작
kubectl rollout restart deployment/thanos-store -n monitoring

# 4. Query 테스트
curl "http://thanos-query:9090/api/v1/query?query=up"
```

### 시나리오 3: 전체 클러스터 손실

**상황**: Cluster-01 (중앙) 전체 장애

**복구 절차**:
1. 새 Kubernetes 클러스터 생성
2. S3 백업에서 TSDB 블록 복원
3. Velero로 ConfigMap/Secret 복원
4. Thanos 컴포넌트 재배포
5. Agent Remote Write 재연결

**RTO**: 1시간
**RPO**: 15분 (마지막 Snapshot)

```bash
# 1. 클러스터 생성 (생략)

# 2. S3 블록 접근 확인
mc ls minio-backup/thanos-cluster-01-backup

# 3. Velero 복원
velero restore create --from-backup monitoring-backup-20251020

# 4. Kustomize 배포
kustomize build deploy/overlays/cluster-01-central --enable-helm | kubectl apply -f -

# 5. Agent 확인
kubectl logs -n monitoring prometheus-agent-0 | grep "remote write"
```

---

## 9️⃣ 백업 검증

### 정기 복구 테스트

```bash
# 월간 복구 테스트 스크립트
#!/bin/bash

echo "=== Backup Recovery Test ==="
echo "Date: $(date)"

# 1. S3 백업 검증
echo "1. Verifying S3 backup..."
BLOCK_COUNT=$(mc ls --recursive minio-backup/thanos-cluster-01-backup | grep meta.json | wc -l)
echo "   S3 Blocks: $BLOCK_COUNT"

# 2. Longhorn Snapshot 검증
echo "2. Verifying Longhorn snapshots..."
SNAPSHOT_COUNT=$(kubectl get volumesnapshot -n monitoring --no-headers | wc -l)
echo "   Snapshots: $SNAPSHOT_COUNT"

# 3. Velero 백업 검증
echo "3. Verifying Velero backups..."
velero backup get | grep Completed | wc -l

# 4. 복원 테스트 (Test Namespace)
echo "4. Testing restore to test namespace..."
velero restore create test-restore-$(date +%Y%m%d) \
  --from-backup monitoring-backup-latest \
  --namespace-mappings monitoring:monitoring-test

# 5. 복원 검증
echo "5. Verifying restored resources..."
kubectl get all -n monitoring-test

echo "=== Test Complete ==="
```

---

## 🎯 백업 체크리스트

### 일일
- [x] S3 Replication 상태 확인
- [x] Longhorn Snapshot 생성 확인 (자동)
- [x] 백업 용량 모니터링

### 주간
- [x] S3 백업 검증 (블록 수 확인)
- [x] Velero 백업 생성
- [x] Grafana 대시보드 Export

### 월간
- [x] 복구 테스트 수행
- [x] 백업 보존 정책 검토
- [x] RTO/RPO 목표 달성 확인
- [x] 백업 스토리지 용량 계획

---

## 🔗 관련 문서

- **Agent 관리** → [Agent-관리.md](./Agent-관리.md)
- **Receiver 관리** → [Receiver-관리.md](./Receiver-관리.md)
- **스토리지 최적화** → [../09-성능-최적화/스토리지-최적화.md](../09-성능-최적화/스토리지-최적화.md)

---

**최종 업데이트**: 2025-10-20
