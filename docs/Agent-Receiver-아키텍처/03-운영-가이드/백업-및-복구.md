# ë°±ì—… ë° ë³µêµ¬

## ğŸ“‹ ê°œìš”

Prometheus Agent + Thanos Receiver í™˜ê²½ì˜ ë°ì´í„° ë°±ì—… ì „ëµê³¼ ì¬í•´ ë³µêµ¬ ì ˆì°¨ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

---

## ğŸ¯ ë°±ì—… ëª©í‘œ

- **RTO (Recovery Time Objective)**: 1ì‹œê°„ ì´ë‚´
- **RPO (Recovery Point Objective)**: 15ë¶„ ì´ë‚´
- **ë°±ì—… ì£¼ê¸°**: ì¼ì¼ (S3 ìë™), ì£¼ê°„ (Longhorn Snapshot)
- **ë³´ì¡´ ê¸°ê°„**: 30ì¼ (ë°±ì—…), 7ì¼ (Snapshot)
- **ë°±ì—… ìœ„ì¹˜**: MinIO S3 (Primary), Longhorn (Secondary)

---

## 1ï¸âƒ£ ë°±ì—… ëŒ€ìƒ

### ë°±ì—… ìš°ì„ ìˆœìœ„

| ì»´í¬ë„ŒíŠ¸ | ìš°ì„ ìˆœìœ„ | ë°±ì—… ë°©ë²• | RPO | RTO |
|---------|---------|----------|-----|-----|
| **S3 TSDB ë¸”ë¡** | P1 (Critical) | MinIO Replication | 0ë¶„ | 15ë¶„ |
| **Prometheus TSDB** | P2 (High) | Longhorn Snapshot | 15ë¶„ | 30ë¶„ |
| **ConfigMap/Secret** | P2 (High) | Git + Velero | 1ì¼ | 15ë¶„ |
| **Grafana ëŒ€ì‹œë³´ë“œ** | P3 (Medium) | Git + DB Backup | 1ì¼ | 1ì‹œê°„ |
| **OpenSearch ë¡œê·¸** | P4 (Low) | S3 Snapshot | 1ì¼ | 2ì‹œê°„ |

---

## 2ï¸âƒ£ S3 ë°±ì—… (TSDB ë¸”ë¡)

### MinIO Bucket Replication

```bash
# MinIO Replication ì„¤ì • (Primary â†’ Backup Site)
mc admin bucket remote add minio/thanos-cluster-01 \
  https://s3-backup.miribit.lab/thanos-cluster-01-backup \
  --service replication \
  --access-key backup-access-key \
  --secret-key backup-secret-key

# Replication Rule ì¶”ê°€
mc replicate add minio/thanos-cluster-01 \
  --remote-bucket thanos-cluster-01-backup \
  --replicate "delete,delete-marker,existing-objects"

# Replication ìƒíƒœ í™•ì¸
mc replicate status minio/thanos-cluster-01

# ì¶œë ¥:
# Replication Status: Enabled
# Remote Target: s3-backup.miribit.lab/thanos-cluster-01-backup
# Rule: Replicate all objects
# Status: Active
```

### S3 ìˆ˜ë™ ë°±ì—… (mc mirror)

```bash
# ì „ì²´ ë²„í‚· ë°±ì—…
mc mirror minio/thanos-cluster-01 minio-backup/thanos-cluster-01-backup

# ì¶œë ¥:
# ...thanos/01HJXXX.../meta.json:  1.2MiB / 1.2MiB â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100%
# ...thanos/01HJXXX.../index:      64KiB / 64KiB  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100%

# ì¦ë¶„ ë°±ì—… (ë³€ê²½ëœ íŒŒì¼ë§Œ)
mc mirror --watch minio/thanos-cluster-01 minio-backup/thanos-cluster-01-backup

# ë°±ì—… ê²€ì¦
mc ls --recursive minio-backup/thanos-cluster-01-backup | wc -l

# ì¶œë ¥: 2500 (íŒŒì¼ ìˆ˜)
```

### S3 ë°±ì—… ìë™í™”

```yaml
# CronJob: S3 Backup
apiVersion: batch/v1
kind: CronJob
metadata:
  name: s3-backup
  namespace: monitoring
spec:
  schedule: "0 2 * * *"  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mc-backup
            image: minio/mc:latest
            command:
            - /bin/sh
            - -c
            - |
              mc alias set minio http://s3.minio.miribit.lab:9000 $ACCESS_KEY $SECRET_KEY
              mc alias set backup http://s3-backup.miribit.lab:9000 $BACKUP_ACCESS_KEY $BACKUP_SECRET_KEY
              mc mirror minio/thanos-cluster-01 backup/thanos-cluster-01-backup
              echo "Backup completed at $(date)"
            env:
            - name: ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: access-key
            - name: SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: secret-key
            - name: BACKUP_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-backup-credentials
                  key: access-key
            - name: BACKUP_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-backup-credentials
                  key: secret-key
          restartPolicy: OnFailure
```

---

## 3ï¸âƒ£ Prometheus TSDB ë°±ì—… (Longhorn Snapshot)

### Longhorn Snapshot ìƒì„±

```yaml
# VolumeSnapshot ìƒì„±
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: prometheus-snapshot-20251020
  namespace: monitoring
spec:
  volumeSnapshotClassName: longhorn-snapshot
  source:
    persistentVolumeClaimName: prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0
```

```bash
# Snapshot ìƒì„±
kubectl apply -f prometheus-snapshot.yaml

# Snapshot ìƒíƒœ í™•ì¸
kubectl get volumesnapshot -n monitoring

# ì¶œë ¥:
# NAME                          READYTOUSE   SOURCEPVC                     AGE
# prometheus-snapshot-20251020  true         prometheus-...-prometheus-0   1m

# Snapshot ìƒì„¸
kubectl describe volumesnapshot -n monitoring prometheus-snapshot-20251020
```

### ìë™ Snapshot (CronJob)

```yaml
# CronJob: Longhorn Snapshot
apiVersion: batch/v1
kind: CronJob
metadata:
  name: prometheus-snapshot
  namespace: monitoring
spec:
  schedule: "0 */6 * * *"  # 6ì‹œê°„ë§ˆë‹¤
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: snapshot-creator
          containers:
          - name: kubectl
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              SNAPSHOT_NAME="prometheus-snapshot-$(date +%Y%m%d-%H%M%S)"
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: $SNAPSHOT_NAME
                namespace: monitoring
              spec:
                volumeSnapshotClassName: longhorn-snapshot
                source:
                  persistentVolumeClaimName: prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0
              EOF
              echo "Snapshot created: $SNAPSHOT_NAME"
          restartPolicy: OnFailure
```

### Snapshot ë³´ì¡´ ì •ì±…

```yaml
# RecurringJob (Longhorn)
apiVersion: longhorn.io/v1beta2
kind: RecurringJob
metadata:
  name: prometheus-snapshot-daily
  namespace: longhorn-system
spec:
  cron: "0 2 * * *"
  task: "snapshot"
  groups:
    - prometheus
  retain: 7  # 7ì¼ ë³´ì¡´
  concurrency: 2
  labels:
    backup: "daily"
```

---

## 4ï¸âƒ£ ConfigMap/Secret ë°±ì—…

### Velero ë°±ì—…

```bash
# Velero ì„¤ì¹˜
velero install \
  --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.8.0 \
  --bucket velero-backup \
  --secret-file ./velero-credentials \
  --backup-location-config region=us-east-1,s3ForcePathStyle="true",s3Url=http://s3.minio.miribit.lab:9000 \
  --snapshot-location-config region=us-east-1

# Backup ìƒì„± (monitoring namespace)
velero backup create monitoring-backup-$(date +%Y%m%d) \
  --include-namespaces monitoring \
  --include-resources configmaps,secrets

# Backup ìƒíƒœ í™•ì¸
velero backup describe monitoring-backup-20251020

# Backup ëª©ë¡
velero backup get

# ì¶œë ¥:
# NAME                        STATUS      CREATED                  EXPIRES
# monitoring-backup-20251020  Completed   2025-10-20 02:00:00 KST  29d
```

### Git ë°±ì—… (GitOps)

```bash
# ConfigMap/Secretì„ Gitì— ë°±ì—…
kubectl get cm,secret -n monitoring -o yaml > backup/monitoring-resources-$(date +%Y%m%d).yaml

# Git Commit
git add backup/
git commit -m "backup: ConfigMaps and Secrets $(date +%Y%m%d)"
git push origin main

# ë°±ì—… ê²€ì¦
git log --oneline | head -5
```

---

## 5ï¸âƒ£ Grafana ëŒ€ì‹œë³´ë“œ ë°±ì—…

### Grafana Database ë°±ì—…

```bash
# Grafana Pod í™•ì¸
kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana

# PostgreSQL ë°±ì—… (Grafana DB)
kubectl exec -it -n monitoring grafana-xxx -- pg_dump grafana > grafana-backup-$(date +%Y%m%d).sql

# ë˜ëŠ” SQLite ë°±ì—… (ê¸°ë³¸ ì„¤ì •)
kubectl cp -n monitoring grafana-xxx:/var/lib/grafana/grafana.db ./grafana-backup-$(date +%Y%m%d).db
```

### Dashboard JSON ë°±ì—… (API)

```bash
# Grafana APIë¡œ ëŒ€ì‹œë³´ë“œ Export
GRAFANA_URL="http://grafana.k8s-cluster-01.miribit.lab"
API_KEY="your-grafana-api-key"

# ëª¨ë“  ëŒ€ì‹œë³´ë“œ ëª©ë¡
curl -s -H "Authorization: Bearer $API_KEY" \
  "$GRAFANA_URL/api/search?type=dash-db" | jq -r '.[].uid' > dashboard-uids.txt

# ê° ëŒ€ì‹œë³´ë“œ JSON ë°±ì—…
while read uid; do
  curl -s -H "Authorization: Bearer $API_KEY" \
    "$GRAFANA_URL/api/dashboards/uid/$uid" | jq .dashboard \
    > "backup/grafana-dashboard-$uid.json"
done < dashboard-uids.txt

echo "Backed up $(wc -l < dashboard-uids.txt) dashboards"
```

---

## 6ï¸âƒ£ OpenSearch ë°±ì—…

### OpenSearch Snapshot Repository ì„¤ì •

```bash
# S3 Snapshot Repository ìƒì„±
curl -X PUT "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup" \
  -H 'Content-Type: application/json' \
  -d '{
    "type": "s3",
    "settings": {
      "bucket": "opensearch-backup",
      "region": "us-east-1",
      "endpoint": "http://s3.minio.miribit.lab:9000",
      "path_style_access": true,
      "compress": true
    }
  }'

# Repository í™•ì¸
curl -X GET "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup"
```

### Snapshot ìƒì„±

```bash
# ëª¨ë“  ì¸ë±ìŠ¤ Snapshot
curl -X PUT "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup/snapshot-$(date +%Y%m%d)" \
  -H 'Content-Type: application/json' \
  -d '{
    "indices": "*",
    "ignore_unavailable": true,
    "include_global_state": false
  }'

# Snapshot ìƒíƒœ í™•ì¸
curl -X GET "http://opensearch.logging.svc.cluster.local:9200/_snapshot/s3_backup/snapshot-20251020"
```

---

## 7ï¸âƒ£ ë³µêµ¬ ì ˆì°¨

### S3 TSDB ë¸”ë¡ ë³µêµ¬

```bash
# ë°±ì—… ë²„í‚·ì—ì„œ ë³µì›
mc mirror minio-backup/thanos-cluster-01-backup minio/thanos-cluster-01

# Thanos Store ì¬ì‹œì‘ (ìƒˆ ë¸”ë¡ ì¸ì‹)
kubectl rollout restart deployment/thanos-store -n monitoring

# ë³µêµ¬ ê²€ì¦
mc ls --recursive minio/thanos-cluster-01 | grep "meta.json" | wc -l

# Thanos Queryì—ì„œ í™•ì¸
curl "http://thanos-query:9090/api/v1/query?query=up" | jq .
```

### Prometheus TSDB ë³µêµ¬ (Longhorn Snapshot)

```yaml
# Snapshotì—ì„œ ìƒˆ PVC ìƒì„±
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-db-restored
  namespace: monitoring
spec:
  storageClassName: longhorn
  dataSource:
    name: prometheus-snapshot-20251020
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
```

```bash
# PVC ìƒì„±
kubectl apply -f prometheus-pvc-restored.yaml

# Prometheus StatefulSet ìˆ˜ì • (ìƒˆ PVC ì‚¬ìš©)
kubectl edit statefulset prometheus-kube-prometheus-stack-prometheus -n monitoring

# volumeClaimTemplates ë³€ê²½:
# - metadata:
#     name: prometheus-db-restored

# StatefulSet ì¬ì‹œì‘
kubectl rollout restart statefulset/prometheus-kube-prometheus-stack-prometheus -n monitoring
```

### ConfigMap/Secret ë³µêµ¬ (Velero)

```bash
# Backup ëª©ë¡ í™•ì¸
velero backup get

# íŠ¹ì • Backup ë³µì›
velero restore create --from-backup monitoring-backup-20251020

# ë³µì› ìƒíƒœ í™•ì¸
velero restore describe monitoring-backup-20251020-restore

# ë³µì› ë¡œê·¸
velero restore logs monitoring-backup-20251020-restore
```

### Grafana ëŒ€ì‹œë³´ë“œ ë³µêµ¬

```bash
# Database ë³µì› (PostgreSQL)
kubectl cp grafana-backup-20251020.sql monitoring/grafana-xxx:/tmp/
kubectl exec -it -n monitoring grafana-xxx -- psql grafana < /tmp/grafana-backup-20251020.sql

# Dashboard JSON ë³µêµ¬ (API)
for file in backup/grafana-dashboard-*.json; do
  curl -X POST "http://grafana:3000/api/dashboards/db" \
    -H "Authorization: Bearer $API_KEY" \
    -H "Content-Type: application/json" \
    -d @$file
done

# Grafana ì¬ì‹œì‘
kubectl rollout restart deployment/grafana -n monitoring
```

### OpenSearch ë³µêµ¬

```bash
# Snapshot ëª©ë¡ í™•ì¸
curl -X GET "http://opensearch:9200/_snapshot/s3_backup/_all"

# íŠ¹ì • Snapshot ë³µì›
curl -X POST "http://opensearch:9200/_snapshot/s3_backup/snapshot-20251020/_restore" \
  -H 'Content-Type: application/json' \
  -d '{
    "indices": "*",
    "ignore_unavailable": true,
    "include_global_state": false
  }'

# ë³µì› ìƒíƒœ í™•ì¸
curl -X GET "http://opensearch:9200/_recovery"
```

---

## 8ï¸âƒ£ ì¬í•´ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: Prometheus Agent ë°ì´í„° ì†ì‹¤

**ìƒí™©**: Agent WAL ì†ìƒ

**ë³µêµ¬ ì ˆì°¨**:
1. Agent Pod ì¬ì‹œì‘ (WAL ìë™ ë³µêµ¬)
2. Remote Write Queue í™•ì¸
3. ë©”íŠ¸ë¦­ ì—°ì†ì„± ê²€ì¦

**RTO**: 5ë¶„
**RPO**: 0ë¶„ (Remote Writeë¡œ ì´ë¯¸ ì „ì†¡ë¨)

```bash
# 1. Pod ì¬ì‹œì‘
kubectl delete pod -n monitoring prometheus-agent-0

# 2. Remote Write í™•ì¸
kubectl logs -n monitoring prometheus-agent-0 | grep "remote write"

# 3. ë©”íŠ¸ë¦­ ì¿¼ë¦¬
curl "http://thanos-query:9090/api/v1/query?query=up{cluster=\"cluster-03\"}"
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: Thanos Receiver ì „ì²´ ì†ì‹¤

**ìƒí™©**: Receiver StatefulSet ì „ì²´ ì‚­ì œ

**ë³µêµ¬ ì ˆì°¨**:
1. S3ì—ì„œ TSDB ë¸”ë¡ í™•ì¸ (ë°±ì—… ì¡´ì¬)
2. Receiver StatefulSet ì¬ë°°í¬
3. Store Gatewayì—ì„œ S3 ë¸”ë¡ ì¡°íšŒ

**RTO**: 15ë¶„
**RPO**: 0ë¶„ (S3ì— ìë™ ì—…ë¡œë“œë¨)

```bash
# 1. S3 ë¸”ë¡ í™•ì¸
mc ls --recursive minio/thanos-cluster-01 | grep meta.json | wc -l

# 2. Receiver ì¬ë°°í¬
kubectl apply -f thanos-receiver.yaml

# 3. Store Gateway ì¬ì‹œì‘
kubectl rollout restart deployment/thanos-store -n monitoring

# 4. Query í…ŒìŠ¤íŠ¸
curl "http://thanos-query:9090/api/v1/query?query=up"
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì „ì²´ í´ëŸ¬ìŠ¤í„° ì†ì‹¤

**ìƒí™©**: Cluster-01 (ì¤‘ì•™) ì „ì²´ ì¥ì• 

**ë³µêµ¬ ì ˆì°¨**:
1. ìƒˆ Kubernetes í´ëŸ¬ìŠ¤í„° ìƒì„±
2. S3 ë°±ì—…ì—ì„œ TSDB ë¸”ë¡ ë³µì›
3. Veleroë¡œ ConfigMap/Secret ë³µì›
4. Thanos ì»´í¬ë„ŒíŠ¸ ì¬ë°°í¬
5. Agent Remote Write ì¬ì—°ê²°

**RTO**: 1ì‹œê°„
**RPO**: 15ë¶„ (ë§ˆì§€ë§‰ Snapshot)

```bash
# 1. í´ëŸ¬ìŠ¤í„° ìƒì„± (ìƒëµ)

# 2. S3 ë¸”ë¡ ì ‘ê·¼ í™•ì¸
mc ls minio-backup/thanos-cluster-01-backup

# 3. Velero ë³µì›
velero restore create --from-backup monitoring-backup-20251020

# 4. Kustomize ë°°í¬
kustomize build deploy/overlays/cluster-01-central --enable-helm | kubectl apply -f -

# 5. Agent í™•ì¸
kubectl logs -n monitoring prometheus-agent-0 | grep "remote write"
```

---

## 9ï¸âƒ£ ë°±ì—… ê²€ì¦

### ì •ê¸° ë³µêµ¬ í…ŒìŠ¤íŠ¸

```bash
# ì›”ê°„ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash

echo "=== Backup Recovery Test ==="
echo "Date: $(date)"

# 1. S3 ë°±ì—… ê²€ì¦
echo "1. Verifying S3 backup..."
BLOCK_COUNT=$(mc ls --recursive minio-backup/thanos-cluster-01-backup | grep meta.json | wc -l)
echo "   S3 Blocks: $BLOCK_COUNT"

# 2. Longhorn Snapshot ê²€ì¦
echo "2. Verifying Longhorn snapshots..."
SNAPSHOT_COUNT=$(kubectl get volumesnapshot -n monitoring --no-headers | wc -l)
echo "   Snapshots: $SNAPSHOT_COUNT"

# 3. Velero ë°±ì—… ê²€ì¦
echo "3. Verifying Velero backups..."
velero backup get | grep Completed | wc -l

# 4. ë³µì› í…ŒìŠ¤íŠ¸ (Test Namespace)
echo "4. Testing restore to test namespace..."
velero restore create test-restore-$(date +%Y%m%d) \
  --from-backup monitoring-backup-latest \
  --namespace-mappings monitoring:monitoring-test

# 5. ë³µì› ê²€ì¦
echo "5. Verifying restored resources..."
kubectl get all -n monitoring-test

echo "=== Test Complete ==="
```

---

## ğŸ¯ ë°±ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼
- [x] S3 Replication ìƒíƒœ í™•ì¸
- [x] Longhorn Snapshot ìƒì„± í™•ì¸ (ìë™)
- [x] ë°±ì—… ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

### ì£¼ê°„
- [x] S3 ë°±ì—… ê²€ì¦ (ë¸”ë¡ ìˆ˜ í™•ì¸)
- [x] Velero ë°±ì—… ìƒì„±
- [x] Grafana ëŒ€ì‹œë³´ë“œ Export

### ì›”ê°„
- [x] ë³µêµ¬ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
- [x] ë°±ì—… ë³´ì¡´ ì •ì±… ê²€í† 
- [x] RTO/RPO ëª©í‘œ ë‹¬ì„± í™•ì¸
- [x] ë°±ì—… ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ê³„íš

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- **Agent ê´€ë¦¬** â†’ [Agent-ê´€ë¦¬.md](./Agent-ê´€ë¦¬.md)
- **Receiver ê´€ë¦¬** â†’ [Receiver-ê´€ë¦¬.md](./Receiver-ê´€ë¦¬.md)
- **ìŠ¤í† ë¦¬ì§€ ìµœì í™”** â†’ [../09-ì„±ëŠ¥-ìµœì í™”/ìŠ¤í† ë¦¬ì§€-ìµœì í™”.md](../09-ì„±ëŠ¥-ìµœì í™”/ìŠ¤í† ë¦¬ì§€-ìµœì í™”.md)

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-20
