빅데이터 dataops 플랫폼에서 1. spark, airflow, trino등 사용자들이 applicaion을 potal을 사용하여 jenkins, argocd , bitbucket을 사용하여 gitops 자동화 배포 구성을 통해 배포 , 2. 배포가 제대로 되었는지 확인 , 3. 서비스 실행시 적절한 자원풀이 있는지 모니터링 (cpu, ram 등 가용량) , 4. 적절하게 분산하여 실행후 계산된 워크로드가 제대로 동작하는지 모니터링. 5 최적화나, 오류발생 대응을 위한 모니터링 , 6 위 과정을 end to end 구간별로 확인할 수 있는 모니터링 시스템의 포털 구성화 드릴다운구조로, 어떻게 구성하면 좋을지 , 서비스 sre전문가, 플랫폼 엔지니어 전문가 회의를 통해 어떻게 구성할지 가이드 및 대시보드 작성을 해줘 , 해당 시스템은 spark, trino, airflow 등이 -> iceberg -> s3 구간을 통해 동작하고 hivemeta, oracle, pvc (isilon, ceph)등 굉장히 복잡하게 동작하고 있어 좋아 대시보드 구성에 대해서 현재 버전에서 조금더 고도화 하기 위해 관련 전문가를 선정하고 각자 롤에 따라 회의를 진행 , 베어메탈 쿠버네티스 플랫폼 운영 , 그 위에 동작하는 빅데이터 플랫폼 운영과 관련된 내용을 전체적으로 다루는 대시보드 구성을 조금더 눈이 편안한 색조합으로 구성하여 고도화 진행하고 대시보드를 작성하여 그라파나에 삽입