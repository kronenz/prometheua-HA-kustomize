# DataOps í”Œë«í¼ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì‚¬ì „ ìš”êµ¬ì‚¬í•­](#ì‚¬ì „-ìš”êµ¬ì‚¬í•­)
3. [Phase 1: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¸í”„ë¼](#phase-1-ë©”íŠ¸ë¦­-ìˆ˜ì§‘-ì¸í”„ë¼)
4. [Phase 2: ëŒ€ì‹œë³´ë“œ ê°œë°œ](#phase-2-ëŒ€ì‹œë³´ë“œ-ê°œë°œ)
5. [Phase 3: ì•Œë¦¼ ë° SLO](#phase-3-ì•Œë¦¼-ë°-slo)
6. [Phase 4: ìµœì í™”](#phase-4-ìµœì í™”)
7. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ğŸ¯ ê°œìš”

ì´ ë¬¸ì„œëŠ” ë¹…ë°ì´í„° DataOps í”Œë«í¼ì˜ End-to-End ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ
ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤.

### ì‹œìŠ¤í…œ ë²”ìœ„

```
[ì‚¬ìš©ì] â†’ Portal
         â†“
[GitOps] â†’ Bitbucket â†’ Jenkins â†’ ArgoCD
         â†“
[App]    â†’ Spark, Airflow, Trino
         â†“
[Data]   â†’ Iceberg â†’ S3, Hive Metastore
         â†“
[Storage]â†’ S3/MinIO, Oracle, Isilon, Ceph
```

### ëª©í‘œ

- âœ… 6ê°œ ê³„ì¸µ ëª¨ë‹ˆí„°ë§
- âœ… End-to-End ì¶”ì 
- âœ… 99.9% ê°€ìš©ì„± ë³´ì¥
- âœ… MTTD < 5ë¶„, MTTR < 30ë¶„

---

## ğŸ”§ ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ë²„ì „ | ìš©ë„ |
|----------|------|------|
| Kubernetes | 1.25+ | ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ |
| Prometheus | 2.45+ | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ |
| Thanos | 0.32+ | ì¥ê¸° ì €ì¥ ë° ë©€í‹°í´ëŸ¬ìŠ¤í„° |
| Grafana | 10.0+ | ì‹œê°í™” |
| kube-prometheus-stack | 55.0+ | Operator ê¸°ë°˜ ë°°í¬ |

### ê¶Œí•œ ìš”êµ¬ì‚¬í•­

```yaml
# ServiceAccount ê¶Œí•œ
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: dataops-monitoring
rules:
  # Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  - apiGroups: [""]
    resources: ["nodes", "services", "endpoints", "pods"]
    verbs: ["get", "list", "watch"]

  # Custom Resources
  - apiGroups: ["monitoring.coreos.com"]
    resources: ["*"]
    verbs: ["*"]

  # Application ë©”íŠ¸ë¦­
  - apiGroups: ["sparkoperator.k8s.io"]
    resources: ["sparkapplications"]
    verbs: ["get", "list", "watch"]
```

---

## ğŸ“Š Phase 1: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¸í”„ë¼

### 1.1 Prometheus Operator ë°°í¬

```bash
# Helm Repository ì¶”ê°€
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Values íŒŒì¼ ìƒì„±
cat > dataops-prometheus-values.yaml <<EOF
prometheus:
  prometheusSpec:
    # ë¦¬ì†ŒìŠ¤ ì„¤ì •
    resources:
      requests:
        cpu: 2000m
        memory: 8Gi
      limits:
        cpu: 4000m
        memory: 16Gi

    # ìŠ¤í† ë¦¬ì§€ ì„¤ì •
    retention: 15d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn
          resources:
            requests:
              storage: 50Gi

    # External Labels
    externalLabels:
      cluster: dataops-prod
      environment: production
      platform: dataops

    # ServiceMonitor ìë™ ê²€ìƒ‰
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false

    # Thanos Sidecar (ì„ íƒì‚¬í•­)
    thanos:
      image: quay.io/thanos/thanos:v0.32.0
      objectStorageConfig:
        name: thanos-s3-config
        key: objstore.yml

    # Remote Write (Thanos Receiver ì‚¬ìš© ì‹œ)
    remoteWrite:
      - url: http://thanos-receive.monitoring.svc:19291/api/v1/receive
        queueConfig:
          capacity: 10000
          maxShards: 10

grafana:
  enabled: true
  adminPassword: admin123

  # Datasource ì„¤ì •
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Thanos Query
          type: prometheus
          url: http://thanos-query.monitoring.svc:9090
          isDefault: true

  # Dashboard ìë™ ë¡œë“œ
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      searchNamespace: ALL
      provider:
        allowUiUpdates: true

# Alert Manager
alertmanager:
  enabled: true
  config:
    route:
      receiver: 'default'
      routes:
        - match:
            severity: critical
          receiver: pagerduty
        - match:
            severity: high
          receiver: slack
    receivers:
      - name: 'default'
      - name: 'pagerduty'
        pagerduty_configs:
          - service_key: '<YOUR_KEY>'
      - name: 'slack'
        slack_configs:
          - channel: '#dataops-ops'
            api_url: '<SLACK_WEBHOOK_URL>'
EOF

# ë°°í¬
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring \
  --create-namespace \
  -f dataops-prometheus-values.yaml
```

### 1.2 ServiceMonitor ìƒì„±

#### Spark Applications

```yaml
# spark-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: spark-applications
  namespace: monitoring
  labels:
    app: spark
spec:
  selector:
    matchLabels:
      spark-role: driver
  namespaceSelector:
    matchNames:
      - spark-jobs
      - data-processing
  endpoints:
    - port: metrics
      interval: 15s
      path: /metrics
      relabelings:
        # Spark App ID
        - sourceLabels: [__meta_kubernetes_pod_label_spark_app_id]
          targetLabel: spark_app_id
          action: replace

        # Executor ID
        - sourceLabels: [__meta_kubernetes_pod_label_spark_executor_id]
          targetLabel: executor_id
          action: replace

        # Job Name
        - sourceLabels: [__meta_kubernetes_pod_annotation_spark_job_name]
          targetLabel: job_name
          action: replace
```

#### Airflow

```yaml
# airflow-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: airflow-statsd
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: airflow-statsd-exporter
  endpoints:
    - port: metrics
      interval: 30s
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_label_dag_id]
          targetLabel: dag_id
```

#### Trino

```yaml
# trino-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: trino
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: trino
      component: coordinator
  endpoints:
    - port: http
      interval: 30s
      path: /v1/metrics
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_label_trino_cluster]
          targetLabel: cluster_name
```

### 1.3 JMX Exporter ë°°í¬

#### Spark Driver/Executor

```yaml
# spark-jmx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-jmx-config
  namespace: spark-jobs
data:
  jmx-exporter-config.yaml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      # JVM ë©”ëª¨ë¦¬
      - pattern: java.lang<type=Memory><>HeapMemoryUsage\.(\w+)
        name: jvm_memory_heap_$1
        type: GAUGE

      # GC
      - pattern: java.lang<name=(\w+), type=GarbageCollector><>CollectionCount
        name: jvm_gc_collection_count
        labels:
          gc: $1
        type: COUNTER

      - pattern: java.lang<name=(\w+), type=GarbageCollector><>CollectionTime
        name: jvm_gc_collection_time_seconds
        labels:
          gc: $1
        type: COUNTER
        valueFactor: 0.001

      # Spark Executor
      - pattern: metrics<name=executor\.(\w+)\.(\w+)><>Value
        name: spark_executor_$1_$2
        type: GAUGE

      # Spark Driver
      - pattern: metrics<name=driver\.(\w+)\.(\w+)><>Value
        name: spark_driver_$1_$2
        type: GAUGE
```

```yaml
# spark-application-with-jmx.yaml
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: example-spark-app
  namespace: spark-jobs
spec:
  driver:
    javaOptions: |
      -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=8090:/opt/jmx_exporter/config.yaml
    volumeMounts:
      - name: jmx-config
        mountPath: /opt/jmx_exporter
  executor:
    javaOptions: |
      -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=8090:/opt/jmx_exporter/config.yaml
    volumeMounts:
      - name: jmx-config
        mountPath: /opt/jmx_exporter
  volumes:
    - name: jmx-config
      configMap:
        name: spark-jmx-config
```

### 1.4 Custom Exporters

#### Iceberg Table Metrics Exporter

```python
# iceberg_exporter.py
from prometheus_client import start_http_server, Gauge, Counter
import time
from pyiceberg.catalog import load_catalog

# Metrics
table_size = Gauge('iceberg_table_size_bytes', 'Table size in bytes', ['database', 'table'])
table_files = Gauge('iceberg_table_files_count', 'Number of data files', ['database', 'table'])
table_snapshots = Gauge('iceberg_table_snapshots_count', 'Number of snapshots', ['database', 'table'])
table_last_update = Gauge('iceberg_table_last_update_timestamp', 'Last update timestamp', ['database', 'table'])

def collect_iceberg_metrics():
    catalog = load_catalog('hive', uri='thrift://hive-metastore:9083')

    for database in catalog.list_namespaces():
        for table_name in catalog.list_tables(database):
            table = catalog.load_table(f"{database}.{table_name}")

            # Table í¬ê¸°
            total_size = sum(file.file_size_in_bytes for file in table.scan().plan_files())
            table_size.labels(database=database, table=table_name).set(total_size)

            # íŒŒì¼ ê°œìˆ˜
            file_count = len(list(table.scan().plan_files()))
            table_files.labels(database=database, table=table_name).set(file_count)

            # Snapshot ê°œìˆ˜
            snapshot_count = len(table.history())
            table_snapshots.labels(database=database, table=table_name).set(snapshot_count)

            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸
            if table.history():
                last_update = table.history()[-1].timestamp_ms / 1000
                table_last_update.labels(database=database, table=table_name).set(last_update)

if __name__ == '__main__':
    start_http_server(8000)
    while True:
        collect_iceberg_metrics()
        time.sleep(300)  # 5ë¶„ë§ˆë‹¤ ìˆ˜ì§‘
```

```dockerfile
# Dockerfile
FROM python:3.9-slim

RUN pip install prometheus-client pyiceberg[hive]

COPY iceberg_exporter.py /app/
WORKDIR /app

CMD ["python", "iceberg_exporter.py"]
```

```yaml
# iceberg-exporter-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: iceberg-exporter
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: iceberg-exporter
  template:
    metadata:
      labels:
        app: iceberg-exporter
    spec:
      containers:
        - name: exporter
          image: dataops/iceberg-exporter:v1.0
          ports:
            - containerPort: 8000
              name: metrics
          env:
            - name: HIVE_METASTORE_URI
              value: "thrift://hive-metastore:9083"
---
apiVersion: v1
kind: Service
metadata:
  name: iceberg-exporter
  namespace: monitoring
  labels:
    app: iceberg-exporter
spec:
  ports:
    - port: 8000
      name: metrics
  selector:
    app: iceberg-exporter
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: iceberg-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: iceberg-exporter
  endpoints:
    - port: metrics
      interval: 5m
```

### 1.5 Recording Rules ì„¤ì •

```yaml
# dataops-recording-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: dataops-recording-rules
  namespace: monitoring
spec:
  groups:
    - name: dataops_platform
      interval: 30s
      rules:
        # ì „ì²´ í”Œë«í¼ ê°€ìš©ì„±
        - record: dataops:platform:availability
          expr: |
            avg(up{job=~"spark.*|airflow.*|trino.*"})

        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
        - record: dataops:cluster:cpu_usage_ratio
          expr: |
            1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))

        - record: dataops:cluster:memory_usage_ratio
          expr: |
            1 - (
              sum(node_memory_MemAvailable_bytes) /
              sum(node_memory_MemTotal_bytes)
            )

    - name: dataops_spark
      interval: 1m
      rules:
        # Spark Job ì„±ê³µë¥ 
        - record: dataops:spark:success_rate_24h
          expr: |
            sum(increase(spark_job_succeeded_total[24h])) /
            (
              sum(increase(spark_job_succeeded_total[24h])) +
              sum(increase(spark_job_failed_total[24h]))
            )

        # Spark Executor í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        - record: dataops:spark:executor_memory_usage_avg
          expr: |
            avg(spark_executor_memory_used_bytes / spark_executor_memory_total_bytes)

        # Spark GC ì‹œê°„ ë¹„ìœ¨
        - record: dataops:spark:gc_time_ratio
          expr: |
            rate(jvm_gc_collection_time_seconds_total{job="spark"}[5m]) /
            rate(jvm_gc_collection_time_seconds_total{job="spark"}[5m] offset 5m)

    - name: dataops_airflow
      interval: 1m
      rules:
        # Airflow DAG ì„±ê³µë¥ 
        - record: dataops:airflow:dag_success_rate_24h
          expr: |
            sum(increase(airflow_dag_succeeded[24h])) /
            sum(increase(airflow_dag_total[24h]))

        # Airflow Scheduler ì§€ì—°
        - record: dataops:airflow:scheduler_lag_seconds
          expr: |
            time() - airflow_scheduler_heartbeat

    - name: dataops_trino
      interval: 1m
      rules:
        # Trino Query ì„±ê³µë¥ 
        - record: dataops:trino:query_success_rate_24h
          expr: |
            sum(increase(trino_execution_query_completed{status="FINISHED"}[24h])) /
            sum(increase(trino_execution_query_completed[24h]))

        # Trino Worker ê°€ìš©ë¥ 
        - record: dataops:trino:worker_availability
          expr: |
            trino_cluster_active_workers / trino_cluster_total_workers

    - name: dataops_storage
      interval: 5m
      rules:
        # S3 ì—ëŸ¬ìœ¨
        - record: dataops:s3:error_rate
          expr: |
            sum(rate(s3_errors_total[5m])) /
            sum(rate(s3_requests_total[5m]))

        # Iceberg ì‘ì€ íŒŒì¼ ë¹„ìœ¨
        - record: dataops:iceberg:small_files_ratio
          expr: |
            sum(iceberg_table_files_count{size_category="small"}) /
            sum(iceberg_table_files_count)

        # ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ì˜ˆì¸¡ (7ì¼ í›„)
        - record: dataops:storage:capacity_forecast_7d
          expr: |
            predict_linear(
              sum(kubelet_volume_stats_used_bytes{persistentvolumeclaim=~".*dataops.*"})[7d:1h],
              7 * 24 * 3600
            )
```

---

## ğŸ“ˆ Phase 2: ëŒ€ì‹œë³´ë“œ ê°œë°œ

### 2.1 ConfigMapìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ ë°°í¬

ëª¨ë“  ëŒ€ì‹œë³´ë“œëŠ” ConfigMapìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ GitOps ë°©ì‹ìœ¼ë¡œ ë°°í¬í•©ë‹ˆë‹¤.

```bash
# ëŒ€ì‹œë³´ë“œ ë””ë ‰í† ë¦¬ êµ¬ì¡°
deploy-new/overlays/cluster-01-central/kube-prometheus-stack/dashboards/dataops/
â”œâ”€â”€ 00-dataops-main-navigation.yaml           # ë©”ì¸ ë„¤ë¹„ê²Œì´ì…˜
â”œâ”€â”€ 01-dataops-gitops-pipeline.yaml          # GitOps ë°°í¬ íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ 02-dataops-resource-capacity.yaml        # ë¦¬ì†ŒìŠ¤ ê°€ìš©ëŸ‰
â”œâ”€â”€ 03-dataops-workload-execution.yaml       # ì›Œí¬ë¡œë“œ ì‹¤í–‰
â”œâ”€â”€ 04-dataops-data-pipeline.yaml            # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ 05-dataops-optimization.yaml             # ìµœì í™” & íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
â””â”€â”€ 06-dataops-e2e-analytics.yaml            # E2E ë¶„ì„
```

### 2.2 kustomization.yamlì— ì¶”ê°€

```yaml
# kustomization.yaml
resources:
  # ... ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ë“¤

  # DataOps ëŒ€ì‹œë³´ë“œ
  - dashboards/dataops/00-dataops-main-navigation.yaml
  - dashboards/dataops/01-dataops-gitops-pipeline.yaml
  - dashboards/dataops/02-dataops-resource-capacity.yaml
  - dashboards/dataops/03-dataops-workload-execution.yaml
  - dashboards/dataops/04-dataops-data-pipeline.yaml
  - dashboards/dataops/05-dataops-optimization.yaml
  - dashboards/dataops/06-dataops-e2e-analytics.yaml
```

### 2.3 ë°°í¬

```bash
# ConfigMap ìƒì„±
kubectl apply -k deploy-new/overlays/cluster-01-central/kube-prometheus-stack/

# Grafana Pod ì¬ì‹œì‘ (ìë™ ë¡œë“œ)
kubectl rollout restart deployment -n monitoring kube-prometheus-stack-grafana

# ëŒ€ì‹œë³´ë“œ ë¡œë“œ í™•ì¸
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana -c grafana-sc-dashboard --tail=50
```

---

## ğŸš¨ Phase 3: ì•Œë¦¼ ë° SLO

### 3.1 Alert Rules ì„¤ì •

```yaml
# dataops-alert-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: dataops-alert-rules
  namespace: monitoring
spec:
  groups:
    - name: dataops_critical
      interval: 1m
      rules:
        # í”Œë«í¼ ë‹¤ìš´
        - alert: DataOpsPlatformDown
          expr: dataops:platform:availability < 0.95
          for: 2m
          labels:
            severity: critical
            component: platform
          annotations:
            summary: "DataOps í”Œë«í¼ ê°€ìš©ì„± ì €í•˜ ({{ $value | humanizePercentage }})"
            description: "ì „ì²´ í”Œë«í¼ ê°€ìš©ì„±ì´ 95% ë¯¸ë§Œì…ë‹ˆë‹¤."

        # OOM Kill ë¹ˆë°œ
        - alert: OOMKillFrequent
          expr: |
            sum(increase(kube_pod_container_status_terminated_reason{
              reason="OOMKilled",
              namespace=~"spark.*|airflow.*|trino.*"
            }[10m])) > 3
          for: 5m
          labels:
            severity: critical
            component: infrastructure
          annotations:
            summary: "OOM Kill ë¹ˆë²ˆ ë°œìƒ ({{ $value }}íšŒ/10ë¶„)"

        # Spark Job ëŒ€ëŸ‰ ì‹¤íŒ¨
        - alert: SparkJobFailureSpike
          expr: |
            (
              sum(increase(spark_job_failed_total[10m])) /
              sum(increase(spark_job_total[10m]))
            ) > 0.2
          for: 5m
          labels:
            severity: critical
            component: spark
          annotations:
            summary: "Spark Job ì‹¤íŒ¨ìœ¨ ê¸‰ì¦ ({{ $value | humanizePercentage }})"

    - name: dataops_high
      interval: 2m
      rules:
        # ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
        - alert: CPUCapacityLow
          expr: dataops:cluster:cpu_usage_ratio > 0.85
          for: 10m
          labels:
            severity: high
            component: infrastructure
          annotations:
            summary: "CPU ìš©ëŸ‰ ë¶€ì¡± ({{ $value | humanizePercentage }})"

        - alert: MemoryCapacityLow
          expr: dataops:cluster:memory_usage_ratio > 0.90
          for: 10m
          labels:
            severity: high
            component: infrastructure
          annotations:
            summary: "ë©”ëª¨ë¦¬ ìš©ëŸ‰ ë¶€ì¡± ({{ $value | humanizePercentage }})"

        # ìŠ¤í† ë¦¬ì§€ ë¶€ì¡±
        - alert: StorageCapacityLow
          expr: |
            (
              sum(kubelet_volume_stats_used_bytes{namespace=~"spark.*|airflow.*|trino.*"}) /
              sum(kubelet_volume_stats_capacity_bytes{namespace=~"spark.*|airflow.*|trino.*"})
            ) > 0.85
          for: 15m
          labels:
            severity: high
            component: storage
          annotations:
            summary: "ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ë¶€ì¡± ({{ $value | humanizePercentage }})"

        # Iceberg ì‘ì€ íŒŒì¼ ë§ìŒ
        - alert: IcebergSmallFilesHigh
          expr: dataops:iceberg:small_files_ratio > 0.5
          for: 1h
          labels:
            severity: high
            component: iceberg
          annotations:
            summary: "Iceberg ì‘ì€ íŒŒì¼ ë¹„ìœ¨ ë†’ìŒ ({{ $value | humanizePercentage }})"
            description: "Compaction í•„ìš”"

    - name: dataops_medium
      interval: 5m
      rules:
        # Slow Query
        - alert: TrinoSlowQueriesHigh
          expr: |
            count(
              trino_query_wall_time_seconds > 600
              and
              trino_query_state == "RUNNING"
            ) > 5
          for: 10m
          labels:
            severity: medium
            component: trino
          annotations:
            summary: "Trino ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë‹¤ìˆ˜ ({{ $value }}ê°œ)"

        # Airflow Scheduler ì§€ì—°
        - alert: AirflowSchedulerLag
          expr: dataops:airflow:scheduler_lag_seconds > 60
          for: 5m
          labels:
            severity: medium
            component: airflow
          annotations:
            summary: "Airflow Scheduler ì§€ì—° ({{ $value }}ì´ˆ)"
```

### 3.2 SLO ì •ì˜

```yaml
# dataops-slo.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: dataops-slo
  namespace: monitoring
spec:
  groups:
    - name: dataops_slo_availability
      interval: 1m
      rules:
        # SLO: 99.9% ê°€ìš©ì„±
        - record: dataops:slo:availability:target
          expr: 0.999

        # SLI: ì‹¤ì œ ê°€ìš©ì„±
        - record: dataops:slo:availability:sli
          expr: dataops:platform:availability

        # Error Budget
        - record: dataops:slo:availability:error_budget
          expr: |
            1 - (
              (1 - dataops:slo:availability:sli) /
              (1 - dataops:slo:availability:target)
            )

        # Burn Rate (1ì‹œê°„ ìœˆë„ìš°)
        - record: dataops:slo:availability:burn_rate_1h
          expr: |
            (
              1 - avg_over_time(dataops:platform:availability[1h])
            ) / (1 - 0.999)

        # Burn Rate (6ì‹œê°„ ìœˆë„ìš°)
        - record: dataops:slo:availability:burn_rate_6h
          expr: |
            (
              1 - avg_over_time(dataops:platform:availability[6h])
            ) / (1 - 0.999)

    - name: dataops_slo_latency
      interval: 1m
      rules:
        # SLO: P95 ë ˆì´í„´ì‹œ < 1ì‹œê°„
        - record: dataops:slo:latency:target_seconds
          expr: 3600

        # SLI: ì‹¤ì œ P95 ë ˆì´í„´ì‹œ
        - record: dataops:slo:latency:sli_seconds
          expr: |
            histogram_quantile(0.95,
              sum(rate(spark_job_duration_seconds_bucket[5m])) by (le)
            )

    - name: dataops_slo_alerts
      interval: 1m
      rules:
        # Error Budget ë¹ ë¥¸ ì†Œì§„ ì•Œë¦¼
        - alert: ErrorBudgetBurnRateCritical
          expr: |
            (
              dataops:slo:availability:burn_rate_1h > 14.4
              and
              dataops:slo:availability:burn_rate_6h > 6
            )
          for: 2m
          labels:
            severity: critical
            slo: availability
          annotations:
            summary: "Error Budget ë¹ ë¥¸ ì†Œì§„ (1ì‹œê°„ ë‚´ 5% ì†Œì§„ ì˜ˆìƒ)"

        - alert: ErrorBudgetBurnRateHigh
          expr: |
            (
              dataops:slo:availability:burn_rate_1h > 7
              and
              dataops:slo:availability:burn_rate_6h > 3
            )
          for: 15m
          labels:
            severity: high
            slo: availability
          annotations:
            summary: "Error Budget ì†Œì§„ ê²½ê³  (6ì‹œê°„ ë‚´ 10% ì†Œì§„ ì˜ˆìƒ)"

        # Error Budget ì†Œì§„ ì„ë°•
        - alert: ErrorBudgetExhausted
          expr: dataops:slo:availability:error_budget < 0.1
          for: 5m
          labels:
            severity: critical
            slo: availability
          annotations:
            summary: "Error Budget ì†Œì§„ ì„ë°• ({{ $value | humanizePercentage }} ë‚¨ìŒ)"
```

---

## âš¡ Phase 4: ìµœì í™”

### 4.1 Recording Rule ìµœì í™”

ìì£¼ ì‚¬ìš©ë˜ëŠ” ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ Recording Ruleë¡œ ì‚¬ì „ ê³„ì‚°:

```yaml
# ëŒ€ì‹œë³´ë“œì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬ë¥¼ Recording Ruleë¡œ ë³€í™˜
- record: dataops:spark:active_jobs_by_namespace
  expr: sum(spark_job_active_count) by (namespace, spark_app_id)

- record: dataops:resource:node_allocatable_ratio
  expr: |
    sum(kube_node_status_allocatable{resource="cpu"}) /
    sum(kube_node_status_capacity{resource="cpu"})
```

### 4.2 ëŒ€ì‹œë³´ë“œ ì¿¼ë¦¬ ìµœì í™”

```
Before:
sum(rate(spark_job_duration_seconds_sum[5m])) by (namespace) /
sum(rate(spark_job_duration_seconds_count[5m])) by (namespace)

After (Recording Rule ì‚¬ìš©):
dataops:spark:job_duration_avg_by_namespace
```

### 4.3 Retention ì •ì±… ìµœì í™”

```yaml
# Prometheus retention
retention: 15d  # Raw ë°ì´í„° 15ì¼

# Thanos downsampling
- resolution: 5m
  retention: 90d

- resolution: 1h
  retention: 1y
```

---

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë©”íŠ¸ë¦­ì´ ìˆ˜ì§‘ë˜ì§€ ì•Šì„ ë•Œ

```bash
# 1. Prometheus Targets í™•ì¸
kubectl port-forward -n monitoring svc/kube-prometheus-stack-prometheus 9090:9090
# http://localhost:9090/targets

# 2. ServiceMonitor í™•ì¸
kubectl get servicemonitor -n monitoring

# 3. Service Label í™•ì¸
kubectl get svc -n <namespace> --show-labels

# 4. Pod Label í™•ì¸
kubectl get pods -n <namespace> --show-labels
```

### ëŒ€ì‹œë³´ë“œê°€ ë¡œë“œë˜ì§€ ì•Šì„ ë•Œ

```bash
# 1. ConfigMap í™•ì¸
kubectl get cm -n monitoring -l grafana_dashboard=1

# 2. Sidecar ë¡œê·¸ í™•ì¸
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana -c grafana-sc-dashboard

# 3. Grafana ì¬ì‹œì‘
kubectl rollout restart deployment -n monitoring kube-prometheus-stack-grafana
```

### ì•Œë¦¼ì´ ë°œì†¡ë˜ì§€ ì•Šì„ ë•Œ

```bash
# 1. AlertManager ìƒíƒœ í™•ì¸
kubectl get alertmanager -n monitoring

# 2. Alert Rule í™•ì¸
kubectl get prometheusrule -n monitoring

# 3. AlertManager UI í™•ì¸
kubectl port-forward -n monitoring svc/kube-prometheus-stack-alertmanager 9093:9093
# http://localhost:9093
```

---

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

1. **Phase 1 ì™„ë£Œ í›„**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê²€ì¦
2. **Phase 2 ì™„ë£Œ í›„**: ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸
3. **Phase 3 ì™„ë£Œ í›„**: ì•Œë¦¼ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜)
4. **Phase 4 ì™„ë£Œ í›„**: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

---

**ë¬¸ì„œ ë²„ì „**: v1.0
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-05
**ì‘ì„±ì**: DataOps Platform Team
