# ============================================================================
# Thanos Ruler - Recording Rule 및 Alert Rule 평가
# ============================================================================
#
# 목적:
#   - Recording Rule 평가: 복잡한 쿼리를 미리 계산하여 저장
#   - Alerting Rule 평가: Alert 조건 확인 및 Alertmanager로 전송
#   - 글로벌 Rule 실행: 모든 클러스터의 데이터를 대상으로 Rule 평가
#
# Prometheus Ruler vs Thanos Ruler:
#   - Prometheus Ruler:
#     * 로컬 Prometheus 데이터만 사용
#     * 단일 클러스터 범위
#     * 빠른 평가 (로컬 데이터)
#
#   - Thanos Ruler:
#     * Thanos Query를 통해 모든 클러스터 데이터 사용
#     * 멀티 클러스터 범위
#     * 글로벌 Alert 및 Recording Rule
#     * 평가 결과를 S3에 저장 (장기 보관)
#
# 주요 기능:
#   1. Recording Rules:
#      - 복잡한 쿼리를 사전 계산하여 새로운 메트릭 생성
#      - 대시보드 쿼리 성능 향상
#      - 예: rate(), sum() 등을 미리 계산
#
#   2. Alerting Rules:
#      - 모든 클러스터 데이터를 기반으로 Alert 조건 평가
#      - Alertmanager로 Alert 전송
#      - 글로벌 Alert (예: 전체 클러스터 CPU 사용률)
#
#   3. gRPC StoreAPI:
#      - Recording Rule 결과를 Thanos Query에 제공
#      - Query에서 Rule 결과 조회 가능
#
#   4. S3 저장:
#      - Rule 평가 결과를 S3에 업로드
#      - 장기 보관 및 히스토리 조회
#
# 데이터 흐름:
#   Thanos Query ← Ruler (Rule 평가) → Alertmanager (Alert)
#                      ↓
#                   S3 (Recording Rule 결과 저장)
#
# ============================================================================

---
# ============================================================================
# Service - Thanos Ruler 서비스
# ============================================================================
apiVersion: v1
kind: Service
metadata:
  name: thanos-ruler
  namespace: monitoring
  labels:
    app: thanos-ruler
spec:
  # Service 타입: ClusterIP
  # - HTTP 및 gRPC 포트 노출
  type: ClusterIP

  ports:
    # HTTP 포트 (10902)
    # - 메트릭 노출: /metrics
    # - Health check: /-/healthy, /-/ready
    # - UI: /rules (Rule 상태 확인), /alerts (Alert 상태)
    - name: http
      port: 10902
      targetPort: 10902

    # gRPC 포트 (10901)
    # - Thanos Query가 StoreAPI를 통해 Recording Rule 결과 조회
    # - Rule 평가 결과를 Query에 제공
    - name: grpc
      port: 10901
      targetPort: 10901

  selector:
    app: thanos-ruler

---
# ============================================================================
# StatefulSet - Thanos Ruler 배포
# ============================================================================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: thanos-ruler
  namespace: monitoring
  labels:
    app: thanos-ruler
spec:
  # Replica 수
  # - 기본: 1개 (소규모 환경)
  # - 권장: 2개 (HA 구성, Alert 중복 전송 방지는 Alertmanager가 처리)
  # - 대규모: 3개 이상 (많은 Rule 분산 처리)
  # 참고: 여러 Ruler가 같은 Rule을 평가하지만 Alertmanager가 중복 제거
  replicas: 1

  # Service 이름
  serviceName: thanos-ruler

  selector:
    matchLabels:
      app: thanos-ruler

  template:
    metadata:
      labels:
        app: thanos-ruler
    spec:
      # ======================================================================
      # ServiceAccount
      # ======================================================================
      # Prometheus Operator의 ServiceAccount 재사용
      # - Kubernetes API 접근 권한 (Pod, Service 등 메타데이터 조회)
      # - Rule에서 kube_* 메트릭 사용 가능
      serviceAccountName: prometheus-kube-prometheus-prometheus

      containers:
        - name: thanos-ruler
          # Thanos 이미지
          # - v0.37.2: 현재 stable 버전
          # - 최신 버전: https://quay.io/repository/thanos/thanos?tab=tags
          image: quay.io/thanos/thanos:v0.37.2

          # ================================================================
          # Thanos Ruler 실행 인자
          # ================================================================
          args:
            # Rule 컴포넌트 실행
            - rule

            # 로그 레벨
            # - debug: Rule 평가 상세 로그 (디버깅)
            # - info: 일반 운영 정보 (권장)
            # - warn: 경고만 (프로덕션)
            # - error: 에러만
            - --log.level=info

            # 데이터 디렉토리
            # - Rule 평가 결과 임시 저장
            # - WAL (Write-Ahead Log) 저장
            # - PVC에 마운트된 경로
            - --data-dir=/var/thanos/ruler

            # Rule 평가 주기
            # - 30초: 30초마다 모든 Rule 평가
            # - 권장값:
            #   * 높은 정확도 필요: 15-30초
            #   * 일반 환경: 30-60초
            #   * 낮은 부하: 60-120초
            # - 짧을수록 빠른 Alert, 높은 CPU 사용
            - --eval-interval=30s

            # Rule 파일 경로
            # - ConfigMap에서 마운트한 Rule 파일
            # - **/*.yaml: 모든 YAML 파일 재귀 로드
            # - 여러 Rule 그룹 지원
            - --rule-file=/etc/thanos-ruler/**/*.yaml

            # Alertmanager URL
            # - Alert 전송 대상
            # - kube-prometheus-stack의 Alertmanager Service
            # - 여러 Alertmanager 지정 가능 (HA)
            # - 예: --alertmanagers.url=http://am1:9093 --alertmanagers.url=http://am2:9093
            - --alertmanagers.url=http://kube-prometheus-stack-alertmanager.monitoring.svc.cluster.local:9093

            # Query API URL
            # - Thanos Query 서비스 주소
            # - Rule 평가 시 메트릭 조회
            # - 모든 클러스터 데이터 사용
            # 중요: Thanos Query를 통해 글로벌 Rule 실행
            - --query=http://thanos-query.monitoring.svc.cluster.local:9090

            # S3 설정 파일
            # - Recording Rule 결과를 S3에 업로드
            # - Secret에서 마운트한 objstore.yml
            # - S3 접근 정보 (bucket, endpoint, credentials)
            - --objstore.config-file=/etc/thanos/objstore.yml

            # 외부 레이블
            # - Recording Rule 결과에 추가될 레이블
            # - rule_replica: Ruler Pod 이름 (HA 구성 시 중복 제거용)
            # - 환경 변수 $(POD_NAME) 사용
            - --label=rule_replica="$(POD_NAME)"

            # 선택적 고급 설정 (필요 시 추가)
            # - --alert.query-url=http://thanos-query.example.com  # Alert 링크 URL
            # - --for-outage-tolerance=1h         # Alert pending 유지 시간
            # - --for-grace-period=10m            # Alert pending 유예 기간
            # - --resend-delay=1m                 # Alert 재전송 간격
            # - --query.http-method=POST          # Query HTTP 메소드 (POST/GET)
            # - --query.timeout=2m                # Query 타임아웃

          # ================================================================
          # 환경 변수
          # ================================================================
          env:
            # POD_NAME: 현재 Pod 이름
            # - rule_replica 레이블에 사용
            # - HA 구성 시 각 Ruler 구분
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name

          # ================================================================
          # 포트 설정
          # ================================================================
          ports:
            # HTTP 포트
            # - UI 및 Health Check
            - name: http
              containerPort: 10902

            # gRPC 포트
            # - StoreAPI (Query가 Recording Rule 결과 조회)
            - name: grpc
              containerPort: 10901

          # ================================================================
          # 볼륨 마운트
          # ================================================================
          volumeMounts:
            # 데이터 디렉토리 (PVC)
            # - Rule 평가 결과 임시 저장
            # - WAL 파일 저장
            - name: data
              mountPath: /var/thanos/ruler

            # S3 설정 (Secret)
            # - objstore.yml 파일
            # - 읽기 전용으로 마운트
            - name: s3-config
              mountPath: /etc/thanos
              readOnly: true

            # Rule 파일 (ConfigMap)
            # - Recording Rule 및 Alerting Rule
            # - 읽기 전용으로 마운트
            - name: rules
              mountPath: /etc/thanos-ruler
              readOnly: true

          # ================================================================
          # 리소스 제한
          # ================================================================
          # 환경별 권장 리소스:
          #
          # 소규모 (Rule < 50개):
          #   requests: cpu=250m, memory=512Mi
          #   limits: cpu=500m, memory=1Gi
          #
          # 중규모 (Rule 50-200개):
          #   requests: cpu=500m, memory=1Gi
          #   limits: cpu=1, memory=2Gi
          #
          # 대규모 (Rule > 200개):
          #   requests: cpu=1, memory=2Gi
          #   limits: cpu=2, memory=4Gi
          #
          # 참고:
          # - CPU: Rule 평가 계산에 사용
          # - 메모리: Rule 결과 저장 및 Query 결과 캐싱
          # - Rule 수와 복잡도에 비례하여 증가
          resources:
            limits:
              cpu: 500m
              memory: 1Gi
            requests:
              cpu: 250m
              memory: 512Mi

          # ================================================================
          # Health Checks
          # ================================================================

          # Liveness Probe (Pod 재시작 판단)
          # - 실패 시 Kubernetes가 Pod 재시작
          # - /-/healthy 엔드포인트 확인
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 10902
            # 초기 지연 시간
            # - 30초: Rule 로드 및 Query 연결 대기
            initialDelaySeconds: 30
            # 확인 주기
            periodSeconds: 10

          # Readiness Probe (트래픽 수신 가능 여부)
          # - 실패 시 Service에서 트래픽 제외
          # - /-/ready 엔드포인트 확인
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 10902
            # 초기 지연 시간
            # - 15초: 초기화 대기
            initialDelaySeconds: 15
            # 확인 주기
            periodSeconds: 5

      # ====================================================================
      # 볼륨 정의
      # ====================================================================
      volumes:
        # S3 설정 Secret
        - name: s3-config
          secret:
            secretName: thanos-s3-config

        # Rule 파일 ConfigMap
        # - thanos-ruler-rules ConfigMap에서 로드
        - name: rules
          configMap:
            name: thanos-ruler-rules

  # ======================================================================
  # PVC 템플릿 (StatefulSet 전용)
  # ======================================================================
  # Pod마다 독립적인 PVC 자동 생성
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        # 접근 모드
        # - ReadWriteOnce: 단일 노드에서만 읽기/쓰기
        accessModes: ["ReadWriteOnce"]

        # 스토리지 클래스
        # - longhorn: 분산 블록 스토리지
        # - 다른 옵션: local-path, nfs, ceph-rbd
        storageClassName: longhorn

        # 스토리지 크기
        # - WAL 및 임시 데이터 저장
        # - 권장 크기:
        #   * 소규모: 1Gi
        #   * 중규모: 5Gi
        #   * 대규모: 10Gi
        # 참고: Rule 수에 비례하여 증가
        resources:
          requests:
            storage: 1Gi

---
# ============================================================================
# ConfigMap - Thanos Ruler Rules
# ============================================================================
# Recording Rule 및 Alerting Rule 정의
apiVersion: v1
kind: ConfigMap
metadata:
  name: thanos-ruler-rules
  namespace: monitoring
data:
  # ========================================================================
  # Thanos 컴포넌트 Alert Rules
  # ========================================================================
  thanos-alerts.yaml: |
    groups:
      # --------------------------------------------------------------------
      # Thanos 시스템 Alert 그룹
      # --------------------------------------------------------------------
      - name: thanos
        # Rule 평가 간격
        # - 30초마다 이 그룹의 모든 Rule 평가
        interval: 30s

        rules:
          # ----------------------------------------------------------------
          # Alert: Thanos Compactor Halted
          # ----------------------------------------------------------------
          # 목적: Compactor가 중지되었을 때 알림
          # 영향: 블록 압축 및 다운샘플링 중단, S3 블록 누적
          # 조치: Compactor 로그 확인, S3 연결 확인
          - alert: ThanosCompactHalted
            # 조건: Compactor halted 메트릭이 1인 경우
            expr: thanos_compactor_halted{job="thanos-compactor"} == 1
            # 5분 동안 지속 시 Alert 발생
            for: 5m
            labels:
              severity: warning  # 심각도: warning (critical/warning/info)
            annotations:
              # Alert 요약
              summary: "Thanos Compactor has halted"
              # Alert 상세 설명
              # - $labels.instance: Compactor Pod 이름
              description: "Thanos Compactor {{ $labels.instance }} has halted"

          # ----------------------------------------------------------------
          # Alert: Thanos Query gRPC Error Rate High
          # ----------------------------------------------------------------
          # 목적: Thanos Query의 gRPC 에러율이 높을 때 알림
          # 영향: 쿼리 실패, 대시보드 데이터 누락
          # 조치: Query 로그 확인, Store 연결 확인, 리소스 확인
          - alert: ThanosQueryGrpcErrorRate
            # 조건: gRPC 에러 비율이 1% 초과
            # - Unknown, ResourceExhausted, Internal, Unavailable 에러
            # - 5분 평균 rate 계산
            expr: rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable",job="thanos-query"}[5m]) > 0.01
            # 5분 동안 지속 시 Alert 발생
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Thanos Query gRPC error rate is high"
              # $value: 에러율 값
              description: "Thanos Query {{ $labels.instance }} gRPC error rate is {{ $value }}"

          # ----------------------------------------------------------------
          # 추가 Alert 예시 (필요 시 활성화)
          # ----------------------------------------------------------------
          # - alert: ThanosStoreGrpcErrorRate
          #   expr: rate(grpc_server_handled_total{grpc_code!="OK",job="thanos-store"}[5m]) > 0.01
          #   for: 5m
          #   labels:
          #     severity: warning
          #   annotations:
          #     summary: "Thanos Store gRPC error rate is high"
          #
          # - alert: ThanosReceiverHttpRequestsFailing
          #   expr: rate(http_requests_total{code=~"5..",job="thanos-receiver"}[5m]) > 0.01
          #   for: 5m
          #   labels:
          #     severity: critical
          #   annotations:
          #     summary: "Thanos Receiver HTTP requests are failing"
          #
          # - alert: ThanosSidecarPrometheusScrapesFailing
          #   expr: rate(thanos_sidecar_prometheus_scrape_failures_total[5m]) > 0.01
          #   for: 5m
          #   labels:
          #     severity: warning
          #   annotations:
          #     summary: "Thanos Sidecar Prometheus scrapes are failing"

  # ========================================================================
  # Recording Rules 예시 (필요 시 추가)
  # ========================================================================
  # recording-rules.yaml: |
  #   groups:
  #     - name: global_recording_rules
  #       interval: 30s
  #       rules:
  #         # 전체 클러스터 CPU 사용률 (미리 계산)
  #         - record: cluster:cpu_usage:rate5m
  #           expr: sum(rate(node_cpu_seconds_total{mode!="idle"}[5m])) by (cluster)
  #
  #         # 전체 클러스터 메모리 사용률 (미리 계산)
  #         - record: cluster:memory_usage:bytes
  #           expr: sum(node_memory_Active_bytes) by (cluster)
  #
  #         # Pod별 CPU 사용률 (미리 계산)
  #         - record: pod:cpu_usage:rate5m
  #           expr: sum(rate(container_cpu_usage_seconds_total[5m])) by (namespace, pod, cluster)

---
# ============================================================================
# ServiceMonitor - Thanos Ruler 메트릭 수집
# ============================================================================
# Prometheus Operator가 Thanos Ruler의 메트릭을 자동으로 수집하도록 설정
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: thanos-ruler
  namespace: monitoring
  labels:
    app: thanos-ruler
spec:
  # 메트릭 수집 대상 Service
  selector:
    matchLabels:
      app: thanos-ruler

  # 수집 설정
  endpoints:
    # HTTP 포트에서 메트릭 수집
    - port: http
      # 수집 간격
      # - 30초: 일반적인 간격
      # - Rule 평가 모니터링용
      interval: 30s

# ============================================================================
# 운영 가이드
# ============================================================================
#
# 1. 배포 확인:
#    kubectl get pods -n monitoring -l app=thanos-ruler
#    kubectl get svc -n monitoring thanos-ruler
#
# 2. Rule 상태 확인:
#    kubectl port-forward -n monitoring svc/thanos-ruler 10902:10902
#    # 브라우저: http://localhost:10902/rules
#    # Rule 평가 상태, 마지막 평가 시간, 에러 확인
#
# 3. Alert 상태 확인:
#    # Ruler UI
#    http://localhost:10902/alerts
#    # Active, Pending, Firing Alert 확인
#
# 4. Rule 로그 확인:
#    kubectl logs -n monitoring thanos-ruler-0 | grep -i "rule"
#    # 출력 예: level=info msg="rule evaluation" duration=50ms
#
# 5. Rule ConfigMap 업데이트:
#    kubectl edit configmap -n monitoring thanos-ruler-rules
#    # 또는
#    kubectl apply -f thanos-ruler.yaml
#    # Rule 자동 리로드 (30초 이내)
#
# 6. Rule 평가 메트릭:
#    # Rule 평가 소요 시간
#    prometheus_rule_evaluation_duration_seconds
#
#    # Rule 평가 실패 수
#    prometheus_rule_evaluation_failures_total
#
#    # Alert 전송 수
#    prometheus_notifications_sent_total
#
# 7. Query 연결 확인:
#    kubectl exec -n monitoring thanos-ruler-0 -- \
#      curl -s http://thanos-query.monitoring.svc.cluster.local:9090/api/v1/query?query=up
#
# 8. Alertmanager 연결 확인:
#    kubectl logs -n monitoring thanos-ruler-0 | grep -i "alertmanager"
#    # 출력 예: level=info msg="Alertmanagers updated"
#
# ============================================================================
# 문제 해결
# ============================================================================
#
# 1. "cannot connect to query":
#    원인: Thanos Query 연결 실패
#    해결:
#      - Query Service 존재 여부 확인
#      - Query Pod Running 확인
#      - 네트워크 정책 확인
#
# 2. "rule evaluation failed":
#    원인: Rule 쿼리 에러 또는 Query 타임아웃
#    해결:
#      - Rule 쿼리 문법 확인
#      - Query에서 직접 쿼리 테스트
#      - Query 타임아웃 증가 (--query.timeout)
#
# 3. "alert not firing":
#    원인: Rule 조건 미충족 또는 Alertmanager 연결 문제
#    해결:
#      - Rule UI에서 조건 확인
#      - Alertmanager Service 확인
#      - Alert 로그 확인
#
# 4. "recording rule not appearing in query":
#    원인: Rule 평가 실패 또는 S3 업로드 실패
#    해결:
#      - Rule 평가 로그 확인
#      - S3 credentials 확인
#      - Ruler gRPC 포트 확인
#
# 5. OOMKilled (메모리 부족):
#    원인: 많은 Rule 또는 복잡한 쿼리
#    해결:
#      - resources.limits.memory 증가
#      - Rule 수 감소 또는 분리
#      - eval-interval 증가
#
# 6. "duplicate alert":
#    원인: 여러 Ruler가 같은 Alert 전송
#    해결:
#      - 정상 동작 (Alertmanager가 중복 제거)
#      - Alertmanager 설정 확인
#
# ============================================================================
# Rule 작성 가이드
# ============================================================================
#
# 1. Recording Rule 작성:
#    - 이름 규칙: level:metric:operation
#      예: cluster:cpu_usage:rate5m
#    - 복잡한 쿼리를 사전 계산
#    - 대시보드 성능 향상
#
# 2. Alerting Rule 작성:
#    - 의미 있는 Alert 이름
#    - for: 일시적 이슈 필터링 (권장: 5-15분)
#    - 명확한 annotations (summary, description)
#    - 적절한 severity (critical/warning/info)
#
# 3. 글로벌 Rule:
#    - 모든 클러스터 데이터 사용
#    - cluster 레이블로 필터링
#    - 예: sum() by (cluster) - 클러스터별 집계
#
# 4. Rule 그룹화:
#    - 관련 Rule을 그룹으로 묶기
#    - 그룹별 interval 설정
#    - 파일별로 분리 가능
#
# 5. 테스트:
#    - Rule 쿼리를 Thanos Query UI에서 먼저 테스트
#    - promtool로 문법 검증
#    - for 시간 짧게 설정하여 테스트 후 증가
#
# ============================================================================
# Recording Rule 예시
# ============================================================================
#
# # 클러스터별 CPU 사용률
# - record: cluster:cpu_usage:rate5m
#   expr: sum(rate(node_cpu_seconds_total{mode!="idle"}[5m])) by (cluster)
#
# # 네임스페이스별 메모리 사용량
# - record: namespace:memory_usage:bytes
#   expr: sum(container_memory_working_set_bytes) by (namespace, cluster)
#
# # Pod별 네트워크 수신 바이트 (5분 평균)
# - record: pod:network_receive:rate5m
#   expr: sum(rate(container_network_receive_bytes_total[5m])) by (pod, namespace, cluster)
#
# ============================================================================
# Alerting Rule 예시
# ============================================================================
#
# # 클러스터 CPU 과부하
# - alert: ClusterCPUOverload
#   expr: cluster:cpu_usage:rate5m > 0.8
#   for: 10m
#   labels:
#     severity: warning
#   annotations:
#     summary: "Cluster CPU usage is high"
#     description: "Cluster {{ $labels.cluster }} CPU usage is {{ $value | humanizePercentage }}"
#
# # Pod 재시작 빈번
# - alert: PodFrequentlyRestarting
#   expr: rate(kube_pod_container_status_restarts_total[15m]) > 0.1
#   for: 5m
#   labels:
#     severity: warning
#   annotations:
#     summary: "Pod is restarting frequently"
#     description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting frequently"
#
# ============================================================================
